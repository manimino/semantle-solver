{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8055fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.spatial.distance import euclidean, pdist, squareform\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edee4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_file() -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Yields the next 'size' vectors in a glove file.\n",
    "    \"\"\"\n",
    "    glove_file = '/mnt/Spookley/datasets/glove/glove.6B.50d.txt'\n",
    "    w_vecs = {}\n",
    "    with tqdm(total=400000) as pbar:\n",
    "        with open(glove_file) as fh:\n",
    "            for line in fh.readlines():\n",
    "                pbar.update(1)\n",
    "                toks = line.strip().split()\n",
    "                word = toks[0]\n",
    "                # non-words like punctuation marks have entries, but we don't want those\n",
    "                if not word.isalnum():  \n",
    "                    continue\n",
    "                # Some bigrams and trigrams are in the dataset. Skip those.\n",
    "                try:\n",
    "                    float(toks[1])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                # No errors, parse the line.\n",
    "                vec = [float(s) for s in toks[1:]]\n",
    "                w_vecs[word] = vec\n",
    "    return w_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be3ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bad5f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(w_vecs: Dict[str, List[float]]) -> Tuple[Dict[int, str], AnnoyIndex]:\n",
    "    for v in w_vecs.values():\n",
    "        GLOVE_VEC_SIZE = len(v)\n",
    "        break\n",
    "    idx_to_word = {}\n",
    "    ann_index = AnnoyIndex(GLOVE_VEC_SIZE, 'euclidean')\n",
    "    with tqdm(total=len(w_vecs)) as pbar:\n",
    "        for i, w in enumerate(w_vecs.keys()):\n",
    "            pbar.update(1)\n",
    "            ann_index.add_item(i, w_vecs[w])\n",
    "            idx_to_word[i] = w\n",
    "    ann_index.build(20) # n trees\n",
    "    return idx_to_word, ann_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "74af7591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e28fd6ac694cb19cb53b9a638b6ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_vecs = read_glove_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "983f102c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336158, 10)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=10)\n",
    "mat_full = np.array([w_vecs[w] for w in w_vecs])\n",
    "mat = pca.fit_transform(mat_full)\n",
    "\n",
    "print(mat.shape)\n",
    "\n",
    "for i, w in enumerate(w_vecs.keys()):\n",
    "    w_vecs[w] = mat[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b4d12732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b430c6677d442eb01ae51741577f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "idx_to_word, ann_index = build_index(w_vecs)  # Takes about an hour and a GB of RAM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34969822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cd1d30f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_point_in_dist(point, dist):\n",
    "    # For when we know the dist but have no idea what direction to travel\n",
    "    vec = np.random.random((len(point)))\n",
    "    vec = vec / scipy.linalg.norm(vec)\n",
    "    vec = vec * dist\n",
    "    return vec+point\n",
    "\n",
    "\n",
    "def directed_point_in_dist(p1, p2, p1_dist, p2_dist):\n",
    "    # Generate a vector using p1 and p2.\n",
    "    # Check if it will point in the general direction of our target.\n",
    "    p1p2 = (p1-p2)\n",
    "    p1p2mag = scipy.linalg.norm(p1p2)\n",
    "    if p1p2mag < 0.00001:\n",
    "        return None, 0\n",
    "    p1p2_unit = p1p2 / p1p2mag\n",
    "    if p1_dist < p2_dist:\n",
    "        # p1 is closer to target\n",
    "        mag = p1_dist\n",
    "        target_point = p1 + p1p2_unit*mag\n",
    "        confidence = (p2_dist-p1_dist) / p1p2mag\n",
    "        assert confidence >= 0\n",
    "    else:\n",
    "        # j is closer to target\n",
    "        # make a vector from j to a target that is dists[j] away\n",
    "        mag = p2_dist\n",
    "        target_point = p2 - p1p2_unit*mag\n",
    "        confidence = (p1_dist-p2_dist) / p1p2mag\n",
    "        assert confidence >= 0\n",
    "    return target_point, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9cb5c254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expect [0,6] (array([0., 6.]), 1.0)\n",
      "expect [0,6] (array([0., 6.]), 1.0)\n"
     ]
    }
   ],
   "source": [
    "# test case - target at [0,6], points on y axis\n",
    "p1 = np.array([0,0])\n",
    "p2 = np.array([0,2])\n",
    "target = np.array([0,6])\n",
    "d1 = euclidean(p1, target)\n",
    "d2 = euclidean(p2, target)\n",
    "print('expect [0,6]', directed_point_in_dist(p1, p2, d1, d2))\n",
    "print('expect [0,6]', directed_point_in_dist(p2, p1, d2, d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "11f9fb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expect [0,3] (array([0.        , 3.41421356]), 0.8740320488976422)\n",
      "expect [0,3] (array([0.        , 3.41421356]), 0.8740320488976422)\n"
     ]
    }
   ],
   "source": [
    "# test case - target at [1,3], points on y axis\n",
    "p1 = np.array([0,0])\n",
    "p2 = np.array([0,2])\n",
    "target = np.array([1,3])\n",
    "d1 = euclidean(p1, target)\n",
    "d2 = euclidean(p2, target)\n",
    "print('expect [1,3]', directed_point_in_dist(p1, p2, d1, d2))\n",
    "print('expect [1,3]', directed_point_in_dist(p2, p1, d2, d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "270ecf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1622776601683795 3.1622776601683795\n",
      "expect zero confidence (array([0.        , 5.16227766]), 0.0)\n",
      "expect zero confidence (array([ 0.        , -3.16227766]), 0.0)\n"
     ]
    }
   ],
   "source": [
    "# test case - target at [3,1], points on y axis\n",
    "p1 = np.array([0,0])\n",
    "p2 = np.array([0,2])\n",
    "target = np.array([3,1])\n",
    "d1 = euclidean(p1, target)\n",
    "d2 = euclidean(p2, target)\n",
    "print(d1, d2)\n",
    "print('expect zero confidence', directed_point_in_dist(p1, p2, d1, d2))\n",
    "print('expect zero confidence', directed_point_in_dist(p2, p1, d2, d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f575ae2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "24d104ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemantleGame():\n",
    "    def __init__(self, w_vecs):\n",
    "        w_list = list(w_vecs.keys())\n",
    "        self.target_word = random.choice(w_list[1000:10000])\n",
    "        self.target_vec = w_vecs[self.target_word]\n",
    "        \n",
    "    def guess(self, word, vec) -> Tuple[bool, float]:\n",
    "        # construct guess\n",
    "        dist = euclidean(vec, self.target_vec)\n",
    "        # check if win\n",
    "        if word == self.target_word:\n",
    "            return True, dist\n",
    "        else:\n",
    "            return False, dist\n",
    "    \n",
    "    def display_guesses(self):\n",
    "        s = []\n",
    "        for g in sorted(self.guesses, key = lambda g: g.dist):\n",
    "            s.append(str(g))\n",
    "        print('\\n'.join(s))\n",
    "        \n",
    "    def __str__(self):\n",
    "        return '\\n'.join('{}: {}'.format(k, v) for k, v in self.__dict__.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fd10184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class Guess:\n",
    "    word: str\n",
    "    num: int\n",
    "    dist: float\n",
    "    \n",
    "class SemantleSolver:\n",
    "    \n",
    "    def __init__(self, game: SemantleGame, n_random_guesses=10):\n",
    "        self.game = game\n",
    "        self.n_random_guesses = n_random_guesses\n",
    "        self.closest_dist = float('inf')\n",
    "        self.guesses = []  # List[Guess]\n",
    "        self.guessed_words = set()  # for fast lookup\n",
    "        self.best_guess = None\n",
    "        \n",
    "        self.EXH_THRESH = 0.5\n",
    "        self.N_RANDOM = 10\n",
    "        self.CONF_THRESH = 0.33\n",
    "        \n",
    "        self.stats = {\n",
    "            'grd_high_conf': 0,\n",
    "            'grd_random_dist': 0,\n",
    "            'times_gradient': 0,\n",
    "            'times_exhaustive': 0,\n",
    "            'times_random': 0,\n",
    "        }\n",
    "        \n",
    "    def _gradient_method(self, w_vecs, ann_index):\n",
    "        # Use gradient method to get a closer guess.\n",
    "        p1 = np.array(w_vecs[self.guesses[-1].word])\n",
    "        p1_dist = self.guesses[-1].dist\n",
    "        \n",
    "        # Consider the few most recent points. \n",
    "        # Try and find one with a vector through p1 that points towards the target.\n",
    "        best_point = None\n",
    "        best_confidence = 0\n",
    "        for i in range(2, min(10, len(self.guesses))):\n",
    "            p2 = np.array(w_vecs[self.guesses[-i].word])\n",
    "            p2_dist = self.guesses[-i].dist\n",
    "            \n",
    "            # where does p2->p1 point? and how well aligned is that spot with the target?\n",
    "            target_point, confidence = directed_point_in_dist(p1, p2, p1_dist, p2_dist)\n",
    "            if confidence > best_confidence:\n",
    "                best_confidence = confidence\n",
    "                best_point = target_point\n",
    "                \n",
    "        if best_confidence < self.CONF_THRESH:\n",
    "            self.stats['grd_random_dist'] += 1\n",
    "            vec = np.array(w_vecs[self.best_guess])\n",
    "            best_point = random_point_in_dist(vec, self.closest_dist)\n",
    "        else:\n",
    "            self.stats['grd_high_conf'] += 1\n",
    "\n",
    "        return best_point\n",
    "\n",
    "    \n",
    "    def find_next_guess(self, w_vecs, ann_index, idx_to_word) -> bool:\n",
    "        if len(self.guesses) < self.N_RANDOM:\n",
    "            self.stats['times_random'] += 1\n",
    "            next_word = random.choice(list(w_vecs.keys()))\n",
    "        elif self.closest_dist > self.EXH_THRESH:\n",
    "            self.stats['times_gradient'] += 1\n",
    "            v = self._gradient_method(w_vecs, ann_index)\n",
    "            idxs_near_best = ann_index.get_nns_by_vector(v, 1000)\n",
    "            for idx in idxs_near_best:\n",
    "                w = idx_to_word[idx]\n",
    "                if w not in self.guessed_words:\n",
    "                    next_word = w\n",
    "                    break\n",
    "        else:\n",
    "            self.stats['times_exhaustive'] += 1\n",
    "            # We're close enough to start exhaustive search\n",
    "            v = w_vecs[self.best_guess]\n",
    "            idxs_near_best = ann_index.get_nns_by_vector(v, 1000)\n",
    "            for idx in idxs_near_best:\n",
    "                w = idx_to_word[idx]\n",
    "                if w not in self.guessed_words:\n",
    "                    next_word = w\n",
    "                    break\n",
    "            \n",
    "        return next_word\n",
    "\n",
    "    def make_guess(self, word):\n",
    "        # guess the word\n",
    "        win, dist = self.game.guess(word, w_vecs[word])\n",
    "        self.guessed_words.add(word)\n",
    "        self.guesses.append(Guess(word=word, dist=dist, num=len(self.guesses)+1))\n",
    "        \n",
    "        # see if this one's better\n",
    "        if self.best_guess is None or dist < self.closest_dist:\n",
    "            print(word, round(dist, 3))\n",
    "            self.closest_dist = dist\n",
    "            self.best_guess = word\n",
    "        \n",
    "        if win:\n",
    "            print(\"I win!\")\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fab29e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e243dd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged\n",
      "elohim 3.272\n",
      "extremity 2.887\n",
      "southwest 2.825\n",
      "kms 2.583\n",
      "km 2.56\n",
      "canton 2.315\n",
      "quebec 2.224\n",
      "metro 1.88\n",
      "shootout 1.832\n",
      "cycling 1.722\n",
      "heysel 1.404\n",
      "subsidiary 1.131\n",
      "merged 0.0\n",
      "I win!\n",
      "{'grd_high_conf': 37, 'grd_random_dist': 11, 'times_gradient': 48, 'times_exhaustive': 0, 'times_random': 10}\n"
     ]
    }
   ],
   "source": [
    "game = SemantleGame(w_vecs)\n",
    "player = SemantleSolver(game)\n",
    "print(game.target_word)\n",
    "won = False\n",
    "while not won:\n",
    "    word = player.find_next_guess(w_vecs, ann_index, idx_to_word)\n",
    "    won = player.make_guess(word)\n",
    "    if len(player.guesses) > 5000:\n",
    "        print('stopped. ')\n",
    "        print('Best guess:', player.best_guess, 'dist:', player.closest_dist)\n",
    "        break\n",
    "        \n",
    "print(player.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6b7ccc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(player.guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba025da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
