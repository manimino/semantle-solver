{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebac6d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.spatial.distance import euclidean, pdist, squareform\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import *\n",
    "\n",
    "from scipy.spatial.distance import cosine as cos_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b4cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_file() -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Yields the next 'size' vectors in a glove file.\n",
    "    \"\"\"\n",
    "    glove_file = '/mnt/Spookley/datasets/glove/glove.6B.50d.txt'\n",
    "    w_vecs = {}\n",
    "    with tqdm(total=400000) as pbar:\n",
    "        with open(glove_file) as fh:\n",
    "            for line in fh.readlines():\n",
    "                pbar.update(1)\n",
    "                toks = line.strip().split()\n",
    "                word = toks[0]\n",
    "                # non-words like punctuation marks have entries, but we don't want those\n",
    "                if not word.isalnum():  \n",
    "                    continue\n",
    "                # Some bigrams and trigrams are in the dataset. Skip those.\n",
    "                try:\n",
    "                    float(toks[1])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                # No errors, parse the line.\n",
    "                vec = [float(s) for s in toks[1:]]\n",
    "                vec = np.array(vec)\n",
    "                vec = vec / np.linalg.norm(vec)\n",
    "                vec = vec.tolist()\n",
    "                w_vecs[word] = vec\n",
    "    return w_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca13942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d96d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(w_vecs: Dict[str, List[float]]) -> Tuple[Dict[int, str], AnnoyIndex]:\n",
    "    for v in w_vecs.values():\n",
    "        GLOVE_VEC_SIZE = len(v)\n",
    "        break\n",
    "    idx_to_word = {}\n",
    "    ann_index = AnnoyIndex(GLOVE_VEC_SIZE, 'euclidean')\n",
    "    with tqdm(total=len(w_vecs)) as pbar:\n",
    "        for i, w in enumerate(w_vecs.keys()):\n",
    "            pbar.update(1)\n",
    "            ann_index.add_item(i, w_vecs[w])\n",
    "            idx_to_word[i] = w\n",
    "    ann_index.build(20) # n trees\n",
    "    return idx_to_word, ann_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac4ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "409e6425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0871c29e870241ebad1d60b24249c9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336158, 20)\n"
     ]
    }
   ],
   "source": [
    "w_vecs = read_glove_file()\n",
    "pca = PCA(n_components=20)\n",
    "mat_full = np.array([w_vecs[w] for w in w_vecs])\n",
    "mat = pca.fit_transform(mat_full)\n",
    "\n",
    "print(mat.shape)\n",
    "for i, w in enumerate(w_vecs.keys()):\n",
    "    w_vecs[w] = mat[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "618d10e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5fc7277f2545db9c376188013b6d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "idx_to_word, ann_index = build_index(w_vecs)  # fast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "664b7749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5060883330250372\n",
      "0.6487490476460706\n",
      "0.9384484231299287\n"
     ]
    }
   ],
   "source": [
    "print(euclidean(w_vecs['strawberry'], w_vecs['peach']))\n",
    "print(euclidean(w_vecs['strawberry'], w_vecs['banana']))\n",
    "print(euclidean(w_vecs['strawberry'], w_vecs['envelope']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "326b8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_point_in_dist(point, dist):\n",
    "    # For when we know the dist but have no idea what direction to travel\n",
    "    vec = np.random.random((len(point)))\n",
    "    vec = vec / scipy.linalg.norm(vec)\n",
    "    vec = vec * dist\n",
    "    return vec+point\n",
    "\n",
    "\n",
    "def directed_point_in_dist(p1, p2, p1_dist, p2_dist):\n",
    "    # Generate a vector using p1 and p2.\n",
    "    # Check if it will point in the general direction of our target.\n",
    "    p1p2 = (p1-p2)\n",
    "    p1p2mag = scipy.linalg.norm(p1p2)\n",
    "    if p1p2mag < 0.00001:\n",
    "        return None, 0\n",
    "    p1p2_unit = p1p2 / p1p2mag\n",
    "    if p1_dist < p2_dist:\n",
    "        # p1 is closer to target\n",
    "        mag = p1_dist\n",
    "        target_point = p1 + p1p2_unit*mag\n",
    "        confidence = (p2_dist-p1_dist) / p1p2mag\n",
    "        assert confidence >= 0\n",
    "    else:\n",
    "        # j is closer to target\n",
    "        # make a vector from j to a target that is dists[j] away\n",
    "        mag = p2_dist\n",
    "        target_point = p2 - p1p2_unit*mag\n",
    "        confidence = (p1_dist-p2_dist) / p1p2mag\n",
    "        assert confidence >= 0\n",
    "    return target_point, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c85ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expect [0,6] (array([0., 6.]), 1.0)\n",
      "expect [0,6] (array([0., 6.]), 1.0)\n"
     ]
    }
   ],
   "source": [
    "# test case - target at [0,6], points on y axis\n",
    "p1 = np.array([0,0])\n",
    "p2 = np.array([0,2])\n",
    "target = np.array([0,6])\n",
    "d1 = euclidean(p1, target)\n",
    "d2 = euclidean(p2, target)\n",
    "print('expect [0,6]', directed_point_in_dist(p1, p2, d1, d2))\n",
    "print('expect [0,6]', directed_point_in_dist(p2, p1, d2, d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28ced8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expect [1,3] (array([0.        , 3.41421356]), 0.8740320488976422)\n",
      "expect [1,3] (array([0.        , 3.41421356]), 0.8740320488976422)\n"
     ]
    }
   ],
   "source": [
    "# test case - target at [1,3], points on y axis\n",
    "p1 = np.array([0,0])\n",
    "p2 = np.array([0,2])\n",
    "target = np.array([1,3])\n",
    "d1 = euclidean(p1, target)\n",
    "d2 = euclidean(p2, target)\n",
    "print('expect [1,3]', directed_point_in_dist(p1, p2, d1, d2))\n",
    "print('expect [1,3]', directed_point_in_dist(p2, p1, d2, d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b0c74df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1622776601683795 3.1622776601683795\n",
      "expect zero confidence (array([0.        , 5.16227766]), 0.0)\n",
      "expect zero confidence (array([ 0.        , -3.16227766]), 0.0)\n"
     ]
    }
   ],
   "source": [
    "# test case - target at [3,1], points on y axis\n",
    "p1 = np.array([0,0])\n",
    "p2 = np.array([0,2])\n",
    "target = np.array([3,1])\n",
    "d1 = euclidean(p1, target)\n",
    "d2 = euclidean(p2, target)\n",
    "print(d1, d2)\n",
    "print('expect zero confidence', directed_point_in_dist(p1, p2, d1, d2))\n",
    "print('expect zero confidence', directed_point_in_dist(p2, p1, d2, d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a89e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9243cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemantleGame():\n",
    "    def __init__(self, w_vecs):\n",
    "        w_list = list(w_vecs.keys())\n",
    "        self.target_word = random.choice(w_list[1000:10000])\n",
    "        self.target_vec = w_vecs[self.target_word]\n",
    "        \n",
    "    def guess(self, word, vec) -> Tuple[bool, float]:\n",
    "        # construct guess\n",
    "        # dist = euclidean(vec, self.target_vec) lol nope!\n",
    "        sim_score = 1-cos_dist(vec, self.target_vec)\n",
    "        dist = max(0.1062384 - (-0.75038136)*sim_score + (0.95045057)*sim_score**2, 0)\n",
    "        # check if win\n",
    "        if word == self.target_word:\n",
    "            return True, dist\n",
    "        else:\n",
    "            return False, dist\n",
    "    \n",
    "    def display_guesses(self):\n",
    "        s = []\n",
    "        for g in sorted(self.guesses, key = lambda g: g.dist):\n",
    "            s.append(str(g))\n",
    "        print('\\n'.join(s))\n",
    "        \n",
    "    def __str__(self):\n",
    "        return '\\n'.join('{}: {}'.format(k, v) for k, v in self.__dict__.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01ca2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class Guess:\n",
    "    word: str\n",
    "    num: int\n",
    "    dist: float\n",
    "    \n",
    "class SemantleSolver:\n",
    "    \n",
    "    def __init__(self, n_random_guesses=2, game=None):\n",
    "        self.n_random_guesses = n_random_guesses\n",
    "        self.closest_dist = float('inf')\n",
    "        self.guesses = []  # List[Guess]\n",
    "        self.guessed_words = set()  # for fast lookup\n",
    "        self.best_guess = None\n",
    "        self.game = game\n",
    "        \n",
    "        self.N_RANDOM = 2\n",
    "        self.CONF_THRESH = 0.33\n",
    "        \n",
    "        self.stats = {\n",
    "            'grd_high_conf': 0,\n",
    "            'grd_random_dist': 0,\n",
    "            'times_gradient': 0,\n",
    "            'times_exhaustive': 0,\n",
    "            'times_random': 0,\n",
    "        }\n",
    "        \n",
    "    def _gradient_method(self, w_vecs, ann_index):\n",
    "        # Use gradient method to get a closer guess.\n",
    "        p1 = np.array(w_vecs[self.guesses[-1].word])\n",
    "        p1_dist = self.guesses[-1].dist\n",
    "        \n",
    "        # Consider the few most recent points. \n",
    "        # Try and find one with a vector through p1 that points towards the target.\n",
    "        best_point = None\n",
    "        best_confidence = 0\n",
    "        for i in range(2, min(10, len(self.guesses))):\n",
    "            p2 = np.array(w_vecs[self.guesses[-i].word])\n",
    "            p2_dist = self.guesses[-i].dist\n",
    "            \n",
    "            # where does p2->p1 point? and how well aligned is that spot with the target?\n",
    "            target_point, confidence = directed_point_in_dist(p1, p2, p1_dist, p2_dist)\n",
    "            if confidence > best_confidence:\n",
    "                best_confidence = confidence\n",
    "                best_point = target_point\n",
    "                \n",
    "        if best_confidence < self.CONF_THRESH:\n",
    "            self.stats['grd_random_dist'] += 1\n",
    "            vec = np.array(w_vecs[self.best_guess])\n",
    "            best_point = random_point_in_dist(vec, self.closest_dist)\n",
    "        else:\n",
    "            self.stats['grd_high_conf'] += 1\n",
    "\n",
    "        return best_point\n",
    "\n",
    "    \n",
    "    def find_next_guess(self, w_vecs, ann_index, idx_to_word) -> bool:\n",
    "        if len(self.guesses) < self.N_RANDOM:\n",
    "            self.stats['times_random'] += 1\n",
    "            next_word = random.choice(list(w_vecs.keys()))\n",
    "        else:\n",
    "            self.stats['times_gradient'] += 1\n",
    "            v = self._gradient_method(w_vecs, ann_index)\n",
    "            idxs_near_best = ann_index.get_nns_by_vector(v, 1000)\n",
    "            for idx in idxs_near_best:\n",
    "                w = idx_to_word[idx]\n",
    "                if w not in self.guessed_words:\n",
    "                    next_word = w\n",
    "                    break\n",
    "            \n",
    "        return next_word\n",
    "\n",
    "    def make_guess(self, word):\n",
    "        # guess the word\n",
    "        win, dist = self.game.guess(word, w_vecs[word])\n",
    "        self.guessed_words.add(word)\n",
    "        self.guesses.append(Guess(word=word, dist=dist, num=len(self.guesses)+1))\n",
    "        \n",
    "        # see if this one's better\n",
    "        if self.best_guess is None or dist < self.closest_dist:\n",
    "            #print(word, round(dist, 3))\n",
    "            self.closest_dist = dist\n",
    "            self.best_guess = word\n",
    "        \n",
    "        if win:\n",
    "            #print(\"I win!\")\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def add_guess(self, guess, dist):\n",
    "        # Adds a guess from an external source. For playing Real Semantle.\n",
    "        dist = dist / 20  # I guess?!?!\n",
    "        self.guessed_words.add(word)\n",
    "        self.guesses.append(Guess(word=word, dist=dist, num=len(self.guesses)+1))\n",
    "        if self.best_guess is None or dist < self.closest_dist:\n",
    "            #print(word, round(dist, 3))\n",
    "            self.closest_dist = dist\n",
    "            self.best_guess = word\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bc3099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7e9f0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "underwent\n",
      "kicklighter 0.16\n",
      "columnar 0.324\n",
      "rothfield 0.149\n",
      "jurczak 0.036\n",
      "bugatch 0.04\n",
      "southwood 0.087\n",
      "bulcke 0.136\n",
      "bleustein 0.027\n",
      "secureworks 0.074\n",
      "vendetti 0.01\n",
      "polini 0.006\n",
      "bossey 0.085\n",
      "disanza 0.004\n",
      "boorady 0.055\n",
      "devauchelle 0\n",
      "lauby 0.02\n",
      "schabas 0\n",
      "palissy 0\n",
      "pollner 0.046\n",
      "jennison 0.025\n",
      "bostian 0.006\n",
      "chagolla 0\n",
      "garsson 0\n",
      "tutko 0\n",
      "haeberlin 0\n",
      "mulrow 0.007\n",
      "cargie 0.029\n",
      "kinnucan 0\n",
      "kalbermatten 0\n",
      "gajadhar 0\n",
      "deninger 0\n",
      "prezant 0\n",
      "kranhold 0.018\n",
      "aidala 0\n",
      "crume 0\n",
      "marmaro 0\n",
      "maizels 0\n",
      "caslen 0\n",
      "amparan 0\n",
      "ngobeni 0\n",
      "stremlau 0\n",
      "feldmajer 0\n",
      "slape 0\n",
      "molinelli 0\n",
      "bickell 0\n",
      "costopoulos 0\n",
      "paprocki 0\n",
      "fronstin 0.125\n",
      "degnan 0\n",
      "bvuma 0.013\n",
      "larudee 0.009\n",
      "tullman 0\n",
      "dennerby 0.02\n",
      "deeter 0\n",
      "brucato 0\n",
      "pastrick 0\n",
      "tomaschek 0.055\n",
      "gerns 0\n",
      "naccara 0.086\n",
      "souham 0\n",
      "klesken 0.034\n",
      "clabes 0.04\n",
      "jaczko 0.071\n",
      "bahouth 0\n",
      "buangan 0.003\n",
      "waybourn 0\n",
      "allstetter 0.039\n",
      "koshalek 0\n",
      "longbrake 0.018\n",
      "adjmi 0\n",
      "luterbach 0\n",
      "shamai 0\n",
      "ebersohn 0\n",
      "zuby 0\n",
      "hazlett 0.012\n",
      "theis 0\n",
      "shifrin 0\n",
      "deffenbaugh 0.025\n",
      "deneen 0.035\n",
      "igasaki 0.002\n",
      "cafardi 0\n",
      "rybinsky 0.002\n",
      "leemon 0\n",
      "limandri 0\n",
      "licalsi 0\n",
      "verwilst 0\n",
      "babineau 0.116\n",
      "heezen 0\n",
      "balfe 0\n",
      "mambe 0\n",
      "avello 0\n",
      "coughter 0\n",
      "rentzer 0\n",
      "friedenberg 0\n",
      "garthwaite 0.004\n",
      "railton 0.014\n",
      "mcraven 0\n",
      "prasquier 0\n",
      "skorton 0.034\n",
      "selsberg 0\n",
      "lanzillo 0\n",
      "mutsauki 0\n",
      "truax 0.175\n",
      "selkoe 0.013\n",
      "mcclean 0\n",
      "kielar 0.013\n",
      "balaoing 0\n",
      "estabrook 0.059\n",
      "baumhauer 0\n",
      "lobbering 0.003\n",
      "strachman 0\n",
      "kalmanovitz 0\n",
      "defillippo 0.064\n",
      "kohlhaussen 0.12\n",
      "finnie 0.006\n",
      "klapwijk 0\n",
      "slywotzky 0\n",
      "revesz 0\n",
      "minthorn 0\n",
      "elshoff 0\n",
      "lamberty 0\n",
      "paarlberg 0\n",
      "piecyk 0.067\n",
      "witherell 0\n",
      "ruwe 0\n",
      "slifka 0\n",
      "nojeim 0.03\n",
      "cordani 0\n",
      "polman 0.046\n",
      "durley 0.045\n",
      "kayonga 0\n",
      "edbrooke 0.003\n",
      "zagami 0\n",
      "persse 0\n",
      "scorza 0.082\n",
      "essaye 0\n",
      "shafroth 0.013\n",
      "alverson 0\n",
      "soffen 0.0\n",
      "spaelti 0\n",
      "adee 0\n",
      "halbert 0.006\n",
      "taluto 0\n",
      "hallaren 0\n",
      "hoagland 0.022\n",
      "shumann 0.077\n",
      "gagen 0\n",
      "pecoul 0.015\n",
      "karasyk 0\n",
      "fluhrer 0\n",
      "sokoloski 0\n",
      "laughren 0.093\n",
      "hileman 0\n",
      "sofield 0\n",
      "colglazier 0\n",
      "soller 0\n",
      "klatsky 0\n",
      "ordan 0.039\n",
      "moffit 0.002\n",
      "whyatt 0\n",
      "kayanja 0\n",
      "porcari 0\n",
      "jaine 0\n",
      "schmucker 0\n",
      "deveaux 0.058\n",
      "almy 0\n",
      "hodapp 0.022\n",
      "balestrino 0\n",
      "mangels 0\n",
      "mirelson 0\n",
      "lawsky 0\n",
      "sturcken 0.026\n",
      "colburn 0.065\n",
      "ailor 0.006\n",
      "teeven 0\n",
      "peterffy 0\n",
      "shobin 0\n",
      "baccus 0\n",
      "woocher 0\n",
      "langhammer 0\n",
      "fleuranges 0\n",
      "bernsdorff 0.008\n",
      "padfield 0\n",
      "halamka 0\n",
      "kiley 0.207\n",
      "altschuler 0\n",
      "mankin 0\n",
      "allitt 0\n",
      "clague 0\n",
      "tuller 0\n",
      "stancliffe 0\n",
      "mockett 0\n",
      "bagnato 0\n",
      "solveen 0\n",
      "staddon 0\n",
      "pasquariello 0.001\n",
      "dauth 0\n",
      "stuntz 0\n",
      "okine 0\n",
      "hehir 0.033\n",
      "vericel 0\n",
      "nooter 0.012\n",
      "somerwill 0.092\n",
      "ksiazek 0\n",
      "zaloom 0\n",
      "swiergosz 0.009\n",
      "seyrafi 0\n",
      "golinkin 0\n",
      "thonis 0\n",
      "lassman 0\n",
      "zimuto 0\n",
      "schom 0\n",
      "hisey 0\n",
      "saathoff 0\n",
      "gregorie 0\n",
      "sisson 0\n",
      "gaffey 0.005\n",
      "hosley 0\n",
      "engelmayer 0\n",
      "gernert 0\n",
      "reichler 0\n",
      "bunstine 0\n",
      "mockler 0\n",
      "mccoun 0\n",
      "crossman 0\n",
      "loebbering 0\n",
      "goldgeier 0\n",
      "dilcher 0\n",
      "brinley 0\n",
      "catell 0.01\n",
      "liederman 0\n",
      "ancell 0.044\n",
      "buttenwieser 0.036\n",
      "fasheun 0\n",
      "asseo 0\n",
      "bookstaver 0.035\n",
      "pittle 0.023\n",
      "sanberg 0\n",
      "sibert 0.021\n",
      "obargui 0\n",
      "karges 0\n",
      "shanor 0\n",
      "schifter 0\n",
      "halverson 0\n",
      "zauderer 0.016\n",
      "favish 0\n",
      "dobrzynski 0.08\n",
      "doorley 0\n",
      "vangjel 0.02\n",
      "klingeman 0.007\n",
      "cannadine 0\n",
      "hoefer 0\n",
      "hoerster 0.052\n",
      "agmon 0\n",
      "donkin 0\n",
      "emerman 0\n",
      "kpomakpor 0\n",
      "cikovsky 0\n",
      "hackworth 0.156\n",
      "culleton 0.017\n",
      "crotty 0.187\n",
      "chaffart 0\n",
      "lifson 0\n",
      "schlamm 0.012\n",
      "liacos 0.028\n",
      "benke 0\n",
      "kiesel 0\n",
      "buynak 0.08\n",
      "auriana 0.004\n",
      "hillier 0.056\n",
      "balter 0\n",
      "konaka 0.035\n",
      "prestbo 0\n",
      "weichmann 0.034\n",
      "merkowitz 0\n",
      "castaigne 0\n",
      "langworth 0\n",
      "stacho 0.009\n",
      "zwerling 0\n",
      "schnittger 0\n",
      "strelow 0\n",
      "stites 0\n",
      "theurkauf 0.181\n",
      "degeorge 0\n",
      "noglows 0.077\n",
      "truesdell 0\n",
      "chesbrough 0.004\n",
      "chassin 0\n",
      "bonnette 0\n",
      "abegglen 0\n",
      "ajamie 0.013\n",
      "hungate 0\n",
      "geisst 0.163\n",
      "iwry 0\n",
      "mones 0.083\n",
      "leming 0\n",
      "dupee 0\n",
      "verstegen 0\n",
      "scalea 0\n",
      "satterwhite 0\n",
      "roberston 0.048\n",
      "ransohoff 0.035\n",
      "tinney 0\n",
      "stutchbury 0\n",
      "bushyhead 0\n",
      "schervish 0.019\n",
      "lillehaug 0.0\n",
      "calcagnini 0\n",
      "unmacht 0.005\n",
      "erdman 0.108\n",
      "kadak 0\n",
      "boente 0\n",
      "freinademetz 0.045\n",
      "elstone 0\n",
      "macneish 0\n",
      "adlerstein 0\n",
      "baross 0\n",
      "ledwith 0\n",
      "balet 0\n",
      "niederhuber 0.036\n",
      "tarnopolsky 0\n",
      "drachman 0\n",
      "marren 0\n",
      "urness 0.011\n",
      "bossart 0\n",
      "nimick 0\n",
      "samerjan 0\n",
      "forry 0.073\n",
      "dody 0.029\n",
      "werker 0\n",
      "michale 0\n",
      "gietzen 0\n",
      "herbits 0\n",
      "kaijuka 0.045\n",
      "schlitt 0\n",
      "crossland 0.024\n",
      "keresey 0.051\n",
      "artman 0\n",
      "pradier 0\n",
      "mittelman 0\n",
      "lippert 0.095\n",
      "maikish 0.006\n",
      "brackenbury 0\n",
      "schwertner 0\n",
      "nahmad 0\n",
      "levinstein 0\n",
      "smedley 0.048\n",
      "traynham 0\n",
      "supratman 0\n",
      "lewaravu 0\n",
      "fichter 0\n",
      "freudenstein 0.024\n",
      "leboyer 0.073\n",
      "schenosky 0.053\n",
      "hohlt 0\n",
      "drivon 0\n",
      "saintfiet 0\n",
      "jachnow 0.063\n",
      "evett 0.024\n",
      "whiteford 0\n",
      "lewi 0\n",
      "pasquarello 0\n",
      "garwin 0.032\n",
      "lanahan 0\n",
      "lapalme 0\n",
      "southard 0\n",
      "messitte 0\n",
      "mandanici 0\n",
      "critchlow 0\n",
      "genego 0\n",
      "balsley 0.064\n",
      "shenker 0\n",
      "delalande 0\n",
      "muise 0\n",
      "kochis 0\n",
      "jermoluk 0.166\n",
      "berkey 0.081\n",
      "itkin 0\n",
      "seigfried 0\n",
      "ochterlony 0\n",
      "slemmer 0\n",
      "nides 0\n",
      "snelsire 0.053\n",
      "mocny 0\n",
      "brasillach 0\n",
      "benvenisti 0\n",
      "tinstman 0\n",
      "mashingaidze 0\n",
      "mcluckie 0\n",
      "wuthnow 0.025\n",
      "szymczak 0\n",
      "raup 0\n",
      "sheirer 0.003\n",
      "bilheimer 0\n",
      "madnodje 0\n",
      "ochsenschlager 0.019\n",
      "lighthizer 0.028\n",
      "simels 0\n",
      "gurtner 0.06\n",
      "piest 0.021\n",
      "meskill 0\n",
      "pursell 0\n",
      "feuerstein 0.281\n",
      "mcintire 0.002\n",
      "tunheim 0\n",
      "setliff 0.037\n",
      "ponsor 0.018\n",
      "telesca 0.02\n",
      "arcara 0\n",
      "lasnik 0\n",
      "chatigny 0\n",
      "ryskamp 0\n",
      "czysz 0.019\n",
      "aronsohn 0.048\n",
      "snoddy 0\n",
      "esmerian 0\n",
      "zartman 0\n",
      "pestillo 0.022\n",
      "balser 0\n",
      "gumport 0.026\n",
      "lasri 0\n",
      "hermance 0\n",
      "bickel 0.068\n",
      "trakh 0.027\n",
      "fellmeth 0\n",
      "deandrea 0\n",
      "rondeli 0.07\n",
      "hodulik 0.045\n",
      "coggins 0.084\n",
      "thistlewood 0\n",
      "wientzen 0.025\n",
      "billenness 0\n",
      "merkt 0\n",
      "mccolough 0\n",
      "lanty 0\n",
      "goodmanson 0\n",
      "shotwell 0\n",
      "kunk 0\n",
      "plesser 0\n",
      "barnas 0\n",
      "kuriansky 0.032\n",
      "ramseyer 0\n",
      "rishel 0.053\n",
      "rayment 0\n",
      "hibbard 0.138\n",
      "tefft 0.013\n",
      "mckissack 0\n",
      "warthrop 0\n",
      "rubinger 0\n",
      "breidling 0\n",
      "faletti 0\n",
      "brickner 0\n",
      "ridgley 0.007\n",
      "rydwelski 0.014\n",
      "mikolashek 0.081\n",
      "trossman 0.024\n",
      "foutz 0\n",
      "rosensaft 0.024\n",
      "seyfarth 0.092\n",
      "dyott 0.039\n",
      "reuland 0\n",
      "auwaerter 0\n",
      "southerton 0\n",
      "talbert 0\n",
      "tigue 0\n",
      "bassham 0\n",
      "yannotti 0\n",
      "swomley 0\n",
      "palese 0.01\n",
      "oberhelman 0\n",
      "jenniskens 0.021\n",
      "kilberg 0\n",
      "gunnes 0.044\n",
      "jentleson 0\n",
      "kisner 0\n",
      "ferebee 0\n",
      "brunstad 0.055\n",
      "stahlman 0.133\n",
      "warnke 0.173\n",
      "hanning 0.08\n",
      "laarman 0\n",
      "gomart 0.012\n",
      "margolese 0.018\n",
      "brerewood 0\n",
      "mathiason 0\n",
      "luebke 0\n",
      "kapel 0\n",
      "rutstein 0\n",
      "hagstrom 0.04\n",
      "rapoport 0.095\n",
      "popow 0.019\n",
      "kamins 0.047\n",
      "stavropoulos 0\n",
      "steinbuch 0\n",
      "gitt 0\n",
      "dannemeyer 0\n",
      "aghazarian 0\n",
      "struan 0.024\n",
      "salzberg 0.011\n",
      "adkisson 0\n",
      "depue 0\n",
      "lindheim 0\n",
      "vergnes 0\n",
      "clendenin 0.028\n",
      "ruffner 0.064\n",
      "kaumba 0\n",
      "bergrin 0.165\n",
      "kisembo 0\n",
      "duwan 0.109\n",
      "codner 0\n",
      "dinubile 0\n",
      "schuelke 0.04\n",
      "schmuhl 0.008\n",
      "frisoli 0\n",
      "ezzell 0\n",
      "erxleben 0.019\n",
      "triay 0\n",
      "wetmore 0.151\n",
      "leogrande 0\n",
      "uzzell 0\n",
      "simkins 0\n",
      "ebeling 0.016\n",
      "melsheimer 0\n",
      "loree 0.077\n",
      "goodfellow 0.066\n",
      "shefrin 0.03\n",
      "brinton 0.023\n",
      "wogaman 0.094\n",
      "burgay 0\n",
      "dunkerley 0\n",
      "wauck 0\n",
      "cailliau 0.038\n",
      "leshy 0.07\n",
      "imbroscio 0\n",
      "schear 0\n",
      "wagnon 0\n",
      "habgood 0\n",
      "siklos 0.09\n",
      "schaff 0\n",
      "sutopo 0\n",
      "lorge 0\n",
      "mcilwain 0\n",
      "milbauer 0\n",
      "hanbury 0.099\n",
      "mcwade 0.04\n",
      "jackaman 0\n",
      "sebastianelli 0\n",
      "ltcol 0\n",
      "erlichman 0\n",
      "latz 0\n",
      "velardi 0\n",
      "vergin 0.02\n",
      "mukamal 0\n",
      "goelet 0.043\n",
      "thier 0.166\n",
      "elliff 0\n",
      "nudell 0\n",
      "chovav 0\n",
      "gaffin 0\n",
      "levick 0.154\n",
      "dassey 0\n",
      "sharrett 0\n",
      "dilenschneider 0\n",
      "amburn 0\n",
      "varrone 0\n",
      "beeler 0\n",
      "ruvkun 0\n",
      "gnaizda 0.053\n",
      "kester 0\n",
      "goreau 0\n",
      "katica 0.022\n",
      "cappuccio 0\n",
      "medows 0\n",
      "bienert 0\n",
      "laventhol 0\n",
      "dearington 0.034\n",
      "dartevelle 0.153\n",
      "ciszuk 0\n",
      "spanjers 0\n",
      "yassky 0.066\n",
      "portenoy 0\n",
      "whelton 0\n",
      "mcclay 0.022\n",
      "magliocchetti 0.083\n",
      "pincavage 0.02\n",
      "allardice 0\n",
      "sieracki 0\n",
      "duchossois 0.061\n",
      "borghesani 0\n",
      "essner 0\n",
      "binnington 0.006\n",
      "aldinger 0\n",
      "wenski 0.045\n",
      "schander 0\n",
      "gunby 0.023\n",
      "cortright 0\n",
      "rodgin 0.133\n",
      "casadevall 0\n",
      "hovenden 0\n",
      "stiassny 0\n",
      "kastan 0\n",
      "manspeaker 0.038\n",
      "plaze 0\n",
      "landey 0\n",
      "ussishkin 0.041\n",
      "loftis 0\n",
      "marshak 0\n",
      "gerrity 0.029\n",
      "pickrel 0.02\n",
      "chabraja 0.118\n",
      "tetzchner 0\n",
      "hussman 0.057\n",
      "gilovich 0.024\n",
      "elkan 0\n",
      "ferrandino 0\n",
      "hastie 0.023\n",
      "aronne 0.157\n",
      "lieko 0\n",
      "yochelson 0\n",
      "mandresh 0.128\n",
      "figley 0\n",
      "straniere 0\n",
      "pildes 0.103\n",
      "raynolds 0\n",
      "delongchamps 0.069\n",
      "conal 0\n",
      "hemmingson 0\n",
      "strassberg 0.004\n",
      "plew 0\n",
      "purdon 0\n",
      "tarpinian 0.065\n",
      "curtner 0\n",
      "pulta 0\n",
      "mcculley 0\n",
      "dinham 0.016\n",
      "radsan 0\n",
      "foreyt 0.027\n",
      "eidelberg 0\n",
      "wigington 0\n",
      "kukma 0\n",
      "kaimowitz 0.042\n",
      "senhouse 0\n",
      "embling 0.051\n",
      "nunnelee 0\n",
      "sadove 0\n",
      "erburu 0.093\n",
      "briffault 0\n",
      "littmann 0.011\n",
      "kress 0.278\n",
      "hillyer 0.08\n",
      "eddins 0\n",
      "deleone 0\n",
      "terenzio 0\n",
      "robart 0\n",
      "afrizal 0\n",
      "lakeisha 0\n",
      "avrin 0\n",
      "boze 0\n",
      "leverence 0\n",
      "henrikson 0\n",
      "calomiris 0.076\n",
      "hiltachk 0\n",
      "nadol 0.004\n",
      "hudner 0.078\n",
      "riml 0.053\n",
      "gartland 0\n",
      "galenson 0\n",
      "soneson 0\n",
      "propes 0\n",
      "montefusco 0\n",
      "corgel 0\n",
      "rabkin 0.04\n",
      "musonye 0.034\n",
      "oestreicher 0\n",
      "skeel 0.038\n",
      "meanwell 0\n",
      "giuffra 0.027\n",
      "scocozza 0.082\n",
      "nesvold 0\n",
      "vandewater 0.08\n",
      "herrman 0\n",
      "pannell 0.018\n",
      "robotti 0\n",
      "gerle 0\n",
      "copenhaver 0\n",
      "dadford 0.085\n",
      "cantillon 0\n",
      "troelsen 0.007\n",
      "keinath 0\n",
      "hausser 0\n",
      "stanard 0\n",
      "barram 0.004\n",
      "aney 0\n",
      "groome 0.01\n",
      "ciochon 0\n",
      "dettmer 0\n",
      "poreda 0\n",
      "mueser 0\n",
      "tylman 0\n",
      "klaassen 0\n",
      "pasch 0.121\n",
      "leebaw 0\n",
      "wiedis 0.014\n",
      "kioko 0\n",
      "gurtz 0\n",
      "beistline 0.018\n",
      "gimble 0.05\n",
      "sheketoff 0\n",
      "balliro 0.035\n",
      "fishof 0.014\n",
      "haught 0\n",
      "wilkey 0\n",
      "zebrowski 0\n",
      "kaplowitz 0.033\n",
      "cotchett 0.037\n",
      "afran 0.059\n",
      "fanton 0\n",
      "altbach 0\n",
      "pearsall 0.002\n",
      "barondess 0\n",
      "slesin 0\n",
      "bentwich 0\n",
      "alaniz 0.045\n",
      "bosak 0.103\n",
      "maledon 0\n",
      "labov 0.058\n",
      "reynell 0\n",
      "giblin 0.029\n",
      "brodkin 0\n",
      "dunner 0.037\n",
      "linskey 0\n",
      "soghoian 0\n",
      "mcandrews 0\n",
      "murgor 0\n",
      "bracey 0.082\n",
      "shallman 0\n",
      "wilens 0\n",
      "lannon 0\n",
      "amsalem 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingle 0.099\n",
      "schleifstein 0\n",
      "gozney 0\n",
      "diebitsch 0.063\n",
      "hichens 0\n",
      "werksman 0.102\n",
      "nugee 0\n",
      "reddam 0.035\n",
      "tinlin 0.01\n",
      "glezen 0.018\n",
      "blankinship 0.061\n",
      "leebove 0.02\n",
      "sandall 0.035\n",
      "krell 0\n",
      "sarosdy 0\n",
      "soundararajan 0\n",
      "madhapar 0\n",
      "halldin 0\n",
      "drewniak 0.027\n",
      "krafl 0.025\n",
      "vaanii 0\n",
      "bettinger 0\n",
      "gerlinger 0.062\n",
      "mallinson 0\n",
      "iannarelli 0.014\n",
      "habush 0\n",
      "kasarda 0\n",
      "borovoy 0\n",
      "quasthoff 0.169\n",
      "tourtellotte 0\n",
      "schrier 0\n",
      "devany 0.036\n",
      "lapidus 0.082\n",
      "deboo 0\n",
      "simeza 0\n",
      "sorby 0\n",
      "feitell 0\n",
      "naquin 0\n",
      "harpole 0\n",
      "gristina 0\n",
      "tjoeng 0\n",
      "bearman 0\n",
      "flatau 0\n",
      "rosengard 0\n",
      "raskind 0\n",
      "catalona 0.089\n",
      "wilmers 0\n",
      "leatherdale 0.051\n",
      "begel 0\n",
      "fujine 0.016\n",
      "cecka 0\n",
      "waytha 0\n",
      "colvill 0\n",
      "kasambara 0\n",
      "ferdon 0\n",
      "branum 0\n",
      "sellier 0\n",
      "hershfield 0\n",
      "shinnick 0\n",
      "dattner 0\n",
      "ratey 0\n",
      "degroote 0.048\n",
      "waple 0\n",
      "regner 0\n",
      "katzenstein 0\n",
      "hawksworth 0.008\n",
      "breglio 0\n",
      "blome 0\n",
      "schieck 0\n",
      "toledano 0\n",
      "szymanczyk 0.01\n",
      "dershwitz 0.009\n",
      "qiodravu 0.021\n",
      "ferlauto 0\n",
      "ordesky 0.153\n",
      "richetti 0\n",
      "hullett 0\n",
      "lichenstein 0\n",
      "gilkes 0\n",
      "lillehei 0.016\n",
      "walda 0\n",
      "damond 0\n",
      "greyser 0.014\n",
      "cundall 0\n",
      "risinger 0.011\n",
      "jasny 0\n",
      "riehle 0\n",
      "patin 0.097\n",
      "kleindienst 0.042\n",
      "gershowitz 0\n",
      "newberger 0.062\n",
      "fleitz 0.005\n",
      "goldfrank 0\n",
      "zimmet 0\n",
      "esmie 0.018\n",
      "breitman 0.023\n",
      "buchheit 0.019\n",
      "hackborn 0\n",
      "viteritti 0.046\n",
      "hingson 0.068\n",
      "erichson 0\n",
      "tabackman 0\n",
      "wainberg 0.051\n",
      "spehar 0.094\n",
      "gioiella 0\n",
      "sharenow 0\n",
      "sansing 0\n",
      "revzin 0\n",
      "langmann 0.001\n",
      "lubar 0\n",
      "bicher 0.107\n",
      "dimock 0.012\n",
      "herwitz 0\n",
      "spudis 0\n",
      "mellott 0\n",
      "rueppel 0.102\n",
      "minoo 0\n",
      "zaller 0\n",
      "runkle 0\n",
      "heilbroner 0.081\n",
      "blaser 0.118\n",
      "hameroff 0\n",
      "rogin 0\n",
      "braungart 0.13\n",
      "sathasivam 0\n",
      "ittner 0\n",
      "hitchner 0\n",
      "debaggio 0.129\n",
      "shalli 0.019\n",
      "blumka 0\n",
      "breunig 0\n",
      "segerstrom 0.143\n",
      "willerson 0.021\n",
      "ajok 0.328\n",
      "phimister 0.008\n",
      "parygin 0.024\n",
      "motorin 0.015\n",
      "novitsky 0\n",
      "chifamba 0\n",
      "aprilianto 0\n",
      "thibauld 0\n",
      "boonradom 0\n",
      "nareerat 0\n",
      "zechner 0.128\n",
      "standley 0.035\n",
      "eisele 0\n",
      "chevigny 0.015\n",
      "montrone 0.073\n",
      "decherney 0\n",
      "schoff 0\n",
      "ruppe 0\n",
      "garbe 0.01\n",
      "bottome 0\n",
      "kistner 0\n",
      "rozin 0.114\n",
      "makombe 0.027\n",
      "precht 0\n",
      "thannhauser 0\n",
      "mahowald 0.028\n",
      "dardis 0\n",
      "gundry 0\n",
      "johnie 0\n",
      "lenti 0\n",
      "thodey 0\n",
      "antenen 0.051\n",
      "visotzky 0.082\n",
      "kedrosky 0.064\n",
      "rugh 0\n",
      "glisson 0.054\n",
      "beres 0\n",
      "bleil 0\n",
      "ingebretsen 0\n",
      "middleberg 0\n",
      "slovic 0.062\n",
      "palles 0\n",
      "herro 0.062\n",
      "rendine 0\n",
      "preissler 0\n",
      "charig 0\n",
      "straley 0.017\n",
      "badaracco 0.032\n",
      "messervy 0\n",
      "dorsen 0\n",
      "hinoue 0\n",
      "karpe 0\n",
      "mcmullin 0\n",
      "bulliet 0\n",
      "mabasa 0\n",
      "gronke 0.002\n",
      "arlinghaus 0\n",
      "fabrega 0\n",
      "klarenbeek 0\n",
      "cultrera 0\n",
      "afolayan 0\n",
      "esq 0\n",
      "dameshek 0\n",
      "antigha 0\n",
      "sansaricq 0\n",
      "barnhill 0\n",
      "birren 0\n",
      "jesson 0\n",
      "pingeon 0.017\n",
      "sagebiel 0.049\n",
      "stamboulidis 0.155\n",
      "surbano 0.006\n",
      "tiefer 0\n",
      "cragin 0.022\n",
      "veillon 0\n",
      "bresland 0\n",
      "fenno 0.014\n",
      "herget 0\n",
      "buzhardt 0\n",
      "eichelbaum 0.024\n",
      "gottehrer 0.023\n",
      "quillin 0.011\n",
      "hoopes 0\n",
      "humes 0\n",
      "panter 0\n",
      "mengel 0\n",
      "viadero 0\n",
      "ojiambo 0\n",
      "custred 0.016\n",
      "middlemiss 0\n",
      "dewolf 0.016\n",
      "dyukov 0\n",
      "keevill 0.011\n",
      "mulcaster 0\n",
      "zalkind 0\n",
      "gardephe 0.168\n",
      "cunniff 0\n",
      "faulcon 0.129\n",
      "lauber 0\n",
      "raskob 0.101\n",
      "silbergeld 0.032\n",
      "garone 0\n",
      "asiodu 0\n",
      "obwocha 0.004\n",
      "duckenfield 0\n",
      "lupton 0.067\n",
      "boches 0\n",
      "aamoth 0\n",
      "whitmer 0.148\n",
      "denig 0\n",
      "kpatinde 0.137\n",
      "muellner 0\n",
      "oesterreicher 0\n",
      "hulkower 0.009\n",
      "gholson 0\n",
      "schondelmeyer 0.055\n",
      "naimark 0.115\n",
      "hansjörg 0\n",
      "goffe 0\n",
      "muthoka 0\n",
      "ricciuto 0\n",
      "becklean 0.035\n",
      "dangeard 0.005\n",
      "chesnut 0.02\n",
      "ganchev 0.094\n",
      "kupperman 0\n",
      "meindl 0\n",
      "louden 0.049\n",
      "koppes 0\n",
      "cloward 0\n",
      "givan 0\n",
      "kauzlarich 0.005\n",
      "dejoria 0.031\n",
      "lyster 0\n",
      "searby 0\n",
      "hardoon 0.01\n",
      "steinbruner 0.037\n",
      "aborn 0.064\n",
      "musser 0.027\n",
      "dyches 0\n",
      "henoch 0\n",
      "muegge 0\n",
      "ekstrand 0\n",
      "domhoff 0\n",
      "crissey 0\n",
      "bodinger 0.101\n",
      "stradley 0\n",
      "romankow 0.027\n",
      "preyer 0\n",
      "sopko 0.038\n",
      "jonn 0\n",
      "moinian 0\n",
      "coorsh 0\n",
      "catsimatidis 0.033\n",
      "gescard 0.073\n",
      "mermet 0.005\n",
      "coar 0.055\n",
      "seife 0.031\n",
      "hunnewell 0\n",
      "perel 0\n",
      "rousmaniere 0\n",
      "tysoe 0.017\n",
      "ostrager 0\n",
      "kubes 0\n",
      "yannas 0\n",
      "wallenta 0.044\n",
      "arlie 0\n",
      "iteere 0\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'next_word' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-05cac972198e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_next_guess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mann_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_to_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mwon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_guess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguesses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-7ee6a3709a1b>\u001b[0m in \u001b[0;36mfind_next_guess\u001b[0;34m(self, w_vecs, ann_index, idx_to_word)\u001b[0m\n\u001b[1;32m     69\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_guess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'next_word' referenced before assignment"
     ]
    }
   ],
   "source": [
    "game = SemantleGame(w_vecs)\n",
    "player = SemantleSolver(game=game)\n",
    "print(game.target_word)\n",
    "won = False\n",
    "while not won:\n",
    "    word = player.find_next_guess(w_vecs, ann_index, idx_to_word)\n",
    "    won = player.make_guess(word)\n",
    "    g = player.guesses[-1]\n",
    "    print(g.word, round(g.dist, 3))\n",
    "    if len(player.guesses) > 5000:\n",
    "        print('stopped. ')\n",
    "        print('Best guess:', player.best_guess, 'dist:', player.closest_dist)\n",
    "        break\n",
    "\n",
    "print(player.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3835cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "547ce6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search time.\n",
    "def run_trial(exh, n_rand, conf_thresh, w_vecs, idx_to_word, ann_index):\n",
    "    # make a game\n",
    "    \n",
    "    game = SemantleGame(w_vecs)\n",
    "    player = SemantleSolver(game=game)\n",
    "    \n",
    "    player.EXH_THRESH = exh\n",
    "    player.N_RANDOM = n_rand\n",
    "    player.CONF_THRESH = conf_thresh\n",
    "    \n",
    "    won = False\n",
    "    while not won:\n",
    "        word = player.find_next_guess(w_vecs, ann_index, idx_to_word)\n",
    "        won = player.make_guess(word)\n",
    "        if len(player.guesses) > 1000:\n",
    "            break\n",
    "    return len(player.guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a20833d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2fb07582724cd796d098b122c047c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8d19154f764259bd78f9c681d49322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 0.001, 3, 0.2) 215.85\n",
      "(10, 0.001, 3, 0.3) 193.4\n",
      "(10, 0.001, 3, 0.4) 59.8\n",
      "(10, 0.001, 3, 0.6) 94.4\n",
      "(10, 0.001, 3, 0.8) 324.15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a141a04b584d423cb4437b9b8a1a2d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a12863584a14463ba17622d31332fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 0.001, 3, 0.2) 103.4\n",
      "(15, 0.001, 3, 0.3) 121.1\n",
      "(15, 0.001, 3, 0.4) 84.25\n",
      "(15, 0.001, 3, 0.6) 190.4\n",
      "(15, 0.001, 3, 0.8) 334.25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234ff15c5b744eec9dfd3d686711cceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb301d776ed4083bd4e4e70d2413098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 0.001, 3, 0.2) 151.35\n",
      "(20, 0.001, 3, 0.3) 185.65\n",
      "(20, 0.001, 3, 0.4) 124.6\n",
      "(20, 0.001, 3, 0.6) 220.75\n",
      "(20, 0.001, 3, 0.8) 322.0\n",
      "{(10, 0.001, 3, 0.2): 215.85, (10, 0.001, 3, 0.3): 193.4, (10, 0.001, 3, 0.4): 59.8, (10, 0.001, 3, 0.6): 94.4, (10, 0.001, 3, 0.8): 324.15, (15, 0.001, 3, 0.2): 103.4, (15, 0.001, 3, 0.3): 121.1, (15, 0.001, 3, 0.4): 84.25, (15, 0.001, 3, 0.6): 190.4, (15, 0.001, 3, 0.8): 334.25, (20, 0.001, 3, 0.2): 151.35, (20, 0.001, 3, 0.3): 185.65, (20, 0.001, 3, 0.4): 124.6, (20, 0.001, 3, 0.6): 220.75, (20, 0.001, 3, 0.8): 322.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_dims = [10, 15, 20]\n",
    "exh_threshes = [0.001]\n",
    "n_randoms = [3]\n",
    "conf_threshes = [0.2, 0.3, 0.4, 0.6, 0.8]\n",
    "n_trials = 20\n",
    "\n",
    "params_results = {}\n",
    "\n",
    "for n_dim in n_dims:\n",
    "    \n",
    "    # set up space\n",
    "    w_vecs = read_glove_file()\n",
    "    pca = PCA(n_components=n_dim)\n",
    "    mat_full = np.array([w_vecs[w] for w in w_vecs])\n",
    "    mat = pca.fit_transform(mat_full)\n",
    "\n",
    "    for i, w in enumerate(w_vecs.keys()):\n",
    "        w_vecs[w] = mat[i, :]\n",
    "\n",
    "    idx_to_word, ann_index = build_index(w_vecs)\n",
    "\n",
    "    \n",
    "    for exh in exh_threshes:\n",
    "        for n_rand in n_randoms:\n",
    "            for conf_thresh in conf_threshes:\n",
    "                params = (n_dim, exh, n_rand, conf_thresh)\n",
    "                for trial in range(n_trials):\n",
    "                    n_guesses = run_trial(exh, n_rand, conf_thresh, w_vecs, idx_to_word, ann_index)\n",
    "                    if not params in params_results:\n",
    "                        params_results[params] = 0\n",
    "                    params_results[params] += n_guesses\n",
    "                params_results[params] /= n_trials\n",
    "                print(params, params_results[params])\n",
    "\n",
    "print(params_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c3a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(sorted(zip(params_results.items()), key=lambda x: x[1]))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list(sorted(zip(params_results.items()), key = lambda x: x[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b65bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in ls:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f215f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make something that plays Real Semantle\n",
    "s_play = SemantleSolver()\n",
    "s_play.add_guess('squid', 100-7.04)\n",
    "s_play.add_guess('chiropractor', 100-5.82)\n",
    "s_play.add_guess('dehl', 100+13.61)\n",
    "s_play.add_guess('eighteens', 100+2.08)\n",
    "s_play.add_guess('eighteens', 100-5.23)\n",
    "s_play.add_guess('eighteens', 100+4.49)\n",
    "s_play.add_guess('eighteens', 100+2.76)\n",
    "s_play.find_next_guess(w_vecs, ann_index, idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a3ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534866e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
