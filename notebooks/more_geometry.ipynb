{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131729ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from gensim import models\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.spatial.distance import euclidean, pdist, squareform\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import *\n",
    "\n",
    "from scipy.spatial.distance import cosine as cos_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d3c3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef read_glove_file() -> Dict[str, List[float]]:\\n    #Yields the next 'size' vectors in a glove file.\\n    glove_file = '/mnt/Spookley/datasets/glove/glove.6B.50d.txt'\\n    w_vecs = {}\\n    with tqdm(total=400000) as pbar:\\n        with open(glove_file) as fh:\\n            for line in fh.readlines():\\n                pbar.update(1)\\n                toks = line.strip().split()\\n                word = toks[0]\\n                # non-words like punctuation marks have entries, but we don't want those\\n                if not word.isalnum():  \\n                    continue\\n                # Some bigrams and trigrams are in the dataset. Skip those.\\n                try:\\n                    float(toks[1])\\n                except ValueError:\\n                    continue\\n                # No errors, parse the line.\\n                vec = [float(s) for s in toks[1:]]\\n                vec = np.array(vec)\\n                vec = vec / np.linalg.norm(vec)\\n                vec = vec.tolist()\\n                w_vecs[word] = vec\\n    return w_vecs\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def read_glove_file() -> Dict[str, List[float]]:\n",
    "    #Yields the next 'size' vectors in a glove file.\n",
    "    glove_file = '/mnt/Spookley/datasets/glove/glove.6B.50d.txt'\n",
    "    w_vecs = {}\n",
    "    with tqdm(total=400000) as pbar:\n",
    "        with open(glove_file) as fh:\n",
    "            for line in fh.readlines():\n",
    "                pbar.update(1)\n",
    "                toks = line.strip().split()\n",
    "                word = toks[0]\n",
    "                # non-words like punctuation marks have entries, but we don't want those\n",
    "                if not word.isalnum():  \n",
    "                    continue\n",
    "                # Some bigrams and trigrams are in the dataset. Skip those.\n",
    "                try:\n",
    "                    float(toks[1])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                # No errors, parse the line.\n",
    "                vec = [float(s) for s in toks[1:]]\n",
    "                vec = np.array(vec)\n",
    "                vec = vec / np.linalg.norm(vec)\n",
    "                vec = vec.tolist()\n",
    "                w_vecs[word] = vec\n",
    "    return w_vecs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7389d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_goog_file(size=10000):\n",
    "    vec_file = '/mnt/Spookley/datasets/semantle/GoogleNews-vectors-negative300.bin'\n",
    "    kv = models.KeyedVectors.load_word2vec_format(vec_file, binary=True, limit=size)\n",
    "    words = kv.index_to_key\n",
    "    w_vecs = {}\n",
    "    for w in words:\n",
    "        w_vecs[w] = kv[w] / np.linalg.norm(kv[w])\n",
    "    return w_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88714c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f4fdaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(w_vecs: Dict[str, List[float]]) -> Tuple[Dict[int, str], AnnoyIndex]:\n",
    "    for v in w_vecs.values():\n",
    "        GLOVE_VEC_SIZE = len(v)\n",
    "        break\n",
    "    idx_to_word = {}\n",
    "    ann_index = AnnoyIndex(GLOVE_VEC_SIZE, 'euclidean')\n",
    "    with tqdm(total=len(w_vecs)) as pbar:\n",
    "        for i, w in enumerate(w_vecs.keys()):\n",
    "            pbar.update(1)\n",
    "            ann_index.add_item(i, w_vecs[w])\n",
    "            idx_to_word[i] = w\n",
    "    ann_index.build(20) # n trees\n",
    "    return idx_to_word, ann_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96bc290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8287da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 20)\n"
     ]
    }
   ],
   "source": [
    "w_vecs = read_goog_file(50000)\n",
    "pca = PCA(n_components=20)\n",
    "mat_full = np.array([w_vecs[w] for w in w_vecs])\n",
    "mat = pca.fit_transform(mat_full)\n",
    "\n",
    "print(mat.shape)\n",
    "for i, w in enumerate(w_vecs.keys()):\n",
    "    w_vecs[w] = mat[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328aa71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b26a30aa8474e4fa698eac1fb895f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "idx_to_word, ann_index = build_index(w_vecs)  # fast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b960f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26398617029190063\n",
      "0.3708007335662842\n",
      "0.5318494439125061\n"
     ]
    }
   ],
   "source": [
    "print(euclidean(w_vecs['strawberry'], w_vecs['peach']))\n",
    "print(euclidean(w_vecs['strawberry'], w_vecs['banana']))\n",
    "print(euclidean(w_vecs['strawberry'], w_vecs['envelope']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adabd49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_point_in_dist(point, dist):\n",
    "    # For when we know the dist but have no idea what direction to travel\n",
    "    vec = np.random.random((len(point)))\n",
    "    vec = vec / scipy.linalg.norm(vec)\n",
    "    vec = vec * dist\n",
    "    return vec+point\n",
    "\n",
    "\n",
    "def directed_point_in_dist(p1, p2, p1_dist, p2_dist):\n",
    "    # Generate a vector using p1 and p2.\n",
    "    # Check if it will point in the general direction of our target.\n",
    "    p1p2 = (p1-p2)\n",
    "    p1p2mag = scipy.linalg.norm(p1p2)\n",
    "    if p1p2mag < 0.00001:\n",
    "        return None, 0\n",
    "    p1p2_unit = p1p2 / p1p2mag\n",
    "    if p1_dist < p2_dist:\n",
    "        # p1 is closer to target\n",
    "        mag = p1_dist\n",
    "        target_point = p1 + p1p2_unit*mag\n",
    "        confidence = (p2_dist-p1_dist) / p1p2mag\n",
    "        assert confidence >= 0\n",
    "    else:\n",
    "        # j is closer to target\n",
    "        # make a vector from j to a target that is dists[j] away\n",
    "        mag = p2_dist\n",
    "        target_point = p2 - p1p2_unit*mag\n",
    "        confidence = (p1_dist-p2_dist) / p1p2mag\n",
    "        assert confidence >= 0\n",
    "    return target_point, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0feafb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expect [0,6] (array([0., 6.]), 1.0)\n",
      "expect [0,6] (array([0., 6.]), 1.0)\n"
     ]
    }
   ],
   "source": [
    "# test case - target at [0,6], points on y axis\n",
    "p1 = np.array([0,0])\n",
    "p2 = np.array([0,2])\n",
    "target = np.array([0,6])\n",
    "d1 = euclidean(p1, target)\n",
    "d2 = euclidean(p2, target)\n",
    "print('expect [0,6]', directed_point_in_dist(p1, p2, d1, d2))\n",
    "print('expect [0,6]', directed_point_in_dist(p2, p1, d2, d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da9158d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expect [1,3] (array([0.        , 3.41421356]), 0.8740320488976422)\n",
      "expect [1,3] (array([0.        , 3.41421356]), 0.8740320488976422)\n"
     ]
    }
   ],
   "source": [
    "# test case - target at [1,3], points on y axis\n",
    "p1 = np.array([0,0])\n",
    "p2 = np.array([0,2])\n",
    "target = np.array([1,3])\n",
    "d1 = euclidean(p1, target)\n",
    "d2 = euclidean(p2, target)\n",
    "print('expect [1,3]', directed_point_in_dist(p1, p2, d1, d2))\n",
    "print('expect [1,3]', directed_point_in_dist(p2, p1, d2, d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e820d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1622776601683795 3.1622776601683795\n",
      "expect zero confidence (array([0.        , 5.16227766]), 0.0)\n",
      "expect zero confidence (array([ 0.        , -3.16227766]), 0.0)\n"
     ]
    }
   ],
   "source": [
    "# test case - target at [3,1], points on y axis\n",
    "p1 = np.array([0,0])\n",
    "p2 = np.array([0,2])\n",
    "target = np.array([3,1])\n",
    "d1 = euclidean(p1, target)\n",
    "d2 = euclidean(p2, target)\n",
    "print(d1, d2)\n",
    "print('expect zero confidence', directed_point_in_dist(p1, p2, d1, d2))\n",
    "print('expect zero confidence', directed_point_in_dist(p2, p1, d2, d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5c635b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_dist(score):\n",
    "    sim_score = score / 100\n",
    "    coef = [ 0.45077492,  0.16611714, -0.73503806,  0.55701707]  # google dataset\n",
    "    # coef = [0.04471114, 0.0740919, -0.74640201, 0.95066707] # glove dataset\n",
    "    return coef[0]*sim_score**3 + coef[1]*sim_score**2 + coef[2]*sim_score + coef[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0a31bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemantleGame():\n",
    "    def __init__(self, w_vecs):\n",
    "        w_list = list(w_vecs.keys())\n",
    "        self.target_word = random.choice(w_list[1000:10000])\n",
    "        self.target_vec = w_vecs[self.target_word]\n",
    "        \n",
    "    def guess(self, word, vec) -> Tuple[bool, float]:\n",
    "        # construct guess\n",
    "        # dist = euclidean(vec, self.target_vec) lol nope!\n",
    "        sim_score = 1-cos_dist(vec, self.target_vec)\n",
    "        dist = score_to_dist(sim_score)\n",
    "        # check if win\n",
    "        if word == self.target_word:\n",
    "            return True, dist\n",
    "        else:\n",
    "            return False, dist\n",
    "    \n",
    "    def display_guesses(self):\n",
    "        s = []\n",
    "        for g in sorted(self.guesses, key = lambda g: g.dist):\n",
    "            s.append(str(g))\n",
    "        print('\\n'.join(s))\n",
    "        \n",
    "    def __str__(self):\n",
    "        return '\\n'.join('{}: {}'.format(k, v) for k, v in self.__dict__.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "387f9959",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class Guess:\n",
    "    word: str\n",
    "    num: int\n",
    "    dist: float\n",
    "    \n",
    "class SemantleSolver:\n",
    "    \n",
    "    def __init__(self, n_random_guesses=2, game=None):\n",
    "        self.n_random_guesses = n_random_guesses\n",
    "        self.closest_dist = float('inf')\n",
    "        self.guesses = []  # List[Guess]\n",
    "        self.guessed_words = set()  # for fast lookup\n",
    "        self.best_guess = None\n",
    "        self.game = game\n",
    "        \n",
    "        self.N_RANDOM = 5\n",
    "        self.CONF_THRESH = 0.005\n",
    "        \n",
    "        self.stats = {\n",
    "            'grd_high_conf': 0,\n",
    "            'grd_random_dist': 0,\n",
    "            'times_gradient': 0,\n",
    "            'times_exhaustive': 0,\n",
    "            'times_random': 0,\n",
    "        }\n",
    "        \n",
    "    def _gradient_method(self, w_vecs, ann_index):\n",
    "        # Use gradient method to get a closer guess.\n",
    "        p1 = np.array(w_vecs[self.guesses[-1].word])\n",
    "        p1_dist = self.guesses[-1].dist\n",
    "        \n",
    "        # Consider the few most recent points. \n",
    "        # Try and find one with a vector through p1 that points towards the target.\n",
    "        best_point = None\n",
    "        best_confidence = 0\n",
    "        for i in range(2, min(10, len(self.guesses))):\n",
    "            p2 = np.array(w_vecs[self.guesses[-i].word])\n",
    "            p2_dist = self.guesses[-i].dist\n",
    "            \n",
    "            # where does p2->p1 point? and how well aligned is that spot with the target?\n",
    "            target_point, confidence = directed_point_in_dist(p1, p2, p1_dist, p2_dist)\n",
    "            if confidence > best_confidence:\n",
    "                best_confidence = confidence\n",
    "                best_point = target_point\n",
    "                \n",
    "        if best_confidence < self.CONF_THRESH:\n",
    "            self.stats['grd_random_dist'] += 1\n",
    "            vec = np.array(w_vecs[self.best_guess])\n",
    "            best_point = random_point_in_dist(vec, self.closest_dist)\n",
    "        else:\n",
    "            self.stats['grd_high_conf'] += 1\n",
    "\n",
    "        return best_point\n",
    "\n",
    "    \n",
    "    def find_next_guess(self, w_vecs, ann_index, idx_to_word) -> bool:\n",
    "        if len(self.guesses) < self.N_RANDOM:\n",
    "            self.stats['times_random'] += 1\n",
    "            next_word = random.choice(list(w_vecs.keys()))\n",
    "        else:\n",
    "            self.stats['times_gradient'] += 1\n",
    "            v = self._gradient_method(w_vecs, ann_index)\n",
    "            idxs_near_best = ann_index.get_nns_by_vector(v, 1000)\n",
    "            for idx in idxs_near_best:\n",
    "                w = idx_to_word[idx]\n",
    "                if w not in self.guessed_words:\n",
    "                    next_word = w\n",
    "                    break\n",
    "            \n",
    "        return next_word\n",
    "\n",
    "    def make_guess(self, word):\n",
    "        # guess the word\n",
    "        win, dist = self.game.guess(word, w_vecs[word])\n",
    "        self.guessed_words.add(word)\n",
    "        self.guesses.append(Guess(word=word, dist=dist, num=len(self.guesses)+1))\n",
    "        \n",
    "        # see if this one's better\n",
    "        if self.best_guess is None or dist < self.closest_dist:\n",
    "            #print(word, round(dist, 3))\n",
    "            self.closest_dist = dist\n",
    "            self.best_guess = word\n",
    "        \n",
    "        if win:\n",
    "            #print(\"I win!\")\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def add_guess(self, guess, score):\n",
    "        # Adds a guess from an external source. For playing Real Semantle.\n",
    "        dist = score_to_dist(score)\n",
    "        self.guessed_words.add(word)\n",
    "        self.guesses.append(Guess(word=word, dist=dist, num=len(self.guesses)+1))\n",
    "        if self.best_guess is None or dist < self.closest_dist:\n",
    "            #print(word, round(dist, 3))\n",
    "            self.closest_dist = dist\n",
    "            self.best_guess = word\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c347d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91e5b874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independence\n",
      "0.005\n",
      "Colorado 0.555\n",
      "Gordon_Brown 0.558\n",
      "Mediterranean 0.556\n",
      "recognizing 0.556\n",
      "UDF 0.556\n",
      "Hawai'i 0.555\n",
      "UTSA 0.555\n",
      "Loyola_Marymount 0.556\n",
      "incoming_freshmen 0.556\n",
      "NSU 0.554\n",
      "KC 0.554\n",
      "BHS 0.554\n",
      "LCC 0.554\n",
      "SPC 0.554\n",
      "BBA 0.555\n",
      "TCC 0.553\n",
      "San_Jacinto 0.553\n",
      "Pueblo 0.553\n",
      "La_Salle 0.553\n",
      "Saipan 0.554\n",
      "Elk_Grove 0.554\n",
      "CHS 0.553\n",
      "Laredo 0.555\n",
      "Carthage 0.552\n",
      "Palmyra 0.552\n",
      "Mount_Olive 0.553\n",
      "Zion 0.551\n",
      "Hollow 0.553\n",
      "Alamo 0.553\n",
      "Painting 0.553\n",
      "Custer 0.553\n",
      "Sacred 0.553\n",
      "Morningside 0.553\n",
      "War 0.553\n",
      "Monticello 0.552\n",
      "De_La_Salle 0.554\n",
      "Peninsula 0.553\n",
      "CASA 0.555\n",
      "Crete 0.554\n",
      "revitalizing 0.554\n",
      "Sealy 0.555\n",
      "Villages 0.552\n",
      "Friendship 0.552\n",
      "Retreat 0.553\n",
      "Celebrate 0.554\n",
      "Mercy 0.553\n",
      "Lady 0.552\n",
      "Holy 0.553\n",
      "Mainland 0.555\n",
      "Visitor_Center 0.553\n",
      "Jesuit 0.553\n",
      "Adventist 0.553\n",
      "Woodlands 0.553\n",
      "Abingdon 0.554\n",
      "Guild 0.554\n",
      "Inland 0.552\n",
      "Northeast 0.552\n",
      "Panhandle 0.554\n",
      "AAU 0.555\n",
      "Puget_Sound 0.555\n",
      "Central 0.551\n",
      "Lower 0.553\n",
      "UCA 0.554\n",
      "west 0.554\n",
      "NCC 0.553\n",
      "Longwood 0.553\n",
      "Grand_Bahama 0.555\n",
      "Power_Plant 0.553\n",
      "Northern 0.552\n",
      "Tri 0.552\n",
      "Twin 0.553\n",
      "Ivy 0.554\n",
      "FFA 0.554\n",
      "Western 0.553\n",
      "Lakes 0.552\n",
      "Mt 0.552\n",
      "Equestrian 0.553\n",
      "Mount_Carmel 0.552\n",
      "St._Augustine 0.552\n",
      "Fishermen 0.554\n",
      "Cranberry 0.554\n",
      "Cornerstone 0.552\n",
      "Bahamian 0.556\n",
      "Centerville 0.553\n",
      "Scholastic 0.555\n",
      "Evergreen 0.553\n",
      "Cascade 0.553\n",
      "Ashland 0.553\n",
      "Spalding 0.555\n",
      "Neighborhood 0.552\n",
      "Classroom 0.554\n",
      "city 0.553\n",
      "Oaks 0.553\n",
      "Golf_Course 0.552\n",
      "Sports_Complex 0.553\n",
      "Provident 0.554\n",
      "Jamaica 0.555\n",
      "Horseshoe 0.553\n",
      "Citrus 0.554\n",
      "Ashanti 0.555\n",
      "PHS 0.555\n",
      "Easter 0.556\n",
      "Construction 0.553\n",
      "Textile 0.553\n",
      "Sacred_Heart 0.553\n",
      "Aquinas 0.554\n",
      "Avon 0.554\n",
      "PNC 0.553\n",
      "Catering 0.555\n",
      "Region 0.552\n",
      "State 0.552\n",
      "Generals 0.552\n",
      "Belize 0.554\n",
      "Offensive 0.555\n",
      "state 0.553\n",
      "Digicel 0.557\n",
      "eminent_domain 0.554\n",
      "easements 0.554\n",
      "Peoples 0.552\n",
      "Tribal 0.552\n",
      "Task_Force 0.553\n",
      "Civilian 0.554\n",
      "Military 0.553\n",
      "Ordinance 0.552\n",
      "Removal 0.554\n",
      "Civil_Service 0.554\n",
      "St._Jude 0.557\n",
      "Jihad 0.554\n",
      "Mineral 0.552\n",
      "Timber 0.553\n",
      "Quarry 0.553\n",
      "Mill 0.553\n",
      "Cottage 0.554\n",
      "Colgate 0.555\n",
      "Linfield 0.556\n",
      "Cooperative 0.553\n",
      "Cancer_Society 0.557\n",
      "NE 0.552\n",
      "NM 0.554\n",
      "Chapel 0.553\n",
      "Barn 0.553\n",
      "Swamp 0.552\n",
      "Mud 0.554\n",
      "Gettysburg 0.552\n",
      "Shenandoah 0.553\n",
      "Centralia 0.553\n",
      "Plantation 0.551\n",
      "Freeport 0.552\n",
      "Chatsworth 0.554\n",
      "Farms 0.554\n",
      "Madras 0.554\n",
      "Lumber 0.553\n",
      "Scotiabank 0.556\n",
      "Colony 0.551\n",
      "Shrine 0.552\n",
      "monument 0.553\n",
      "CCA 0.555\n",
      "Gate 0.552\n",
      "Yard 0.552\n",
      "Junction 0.552\n",
      "Road 0.554\n",
      "Naga 0.554\n",
      "Landing 0.552\n",
      "Beverages 0.555\n",
      "Collegiate 0.553\n",
      "Goodwill 0.554\n",
      "Westbury 0.554\n",
      "Alva 0.553\n",
      "Centenary 0.553\n",
      "Wish_Foundation 0.557\n",
      "Fair 0.553\n",
      "Friendly 0.553\n",
      "Editorial 0.554\n",
      "Carmel 0.553\n",
      "Ridgefield 0.554\n",
      "Dubuque 0.554\n",
      "Bahamas 0.556\n",
      "Pleasant_Valley 0.553\n",
      "Edgewood 0.553\n",
      "Glenwood 0.553\n",
      "Indian 0.555\n",
      "Midland 0.553\n",
      "Northwood 0.553\n",
      "Fairview 0.553\n",
      "Lakeview 0.553\n",
      "Elmwood 0.553\n",
      "Westland 0.554\n",
      "Rockford 0.553\n",
      "Trinidad 0.555\n",
      "Cumberland 0.553\n",
      "UB 0.554\n",
      "Boxing 0.555\n",
      "equestrian 0.556\n",
      "Waverly 0.553\n",
      "Richland 0.553\n",
      "Coldwell_Banker 0.555\n",
      "Alumni 0.552\n",
      "Leadership 0.553\n",
      "Senior 0.554\n",
      "Homecoming 0.553\n",
      "Offense 0.555\n",
      "banquet 0.553\n",
      "YWCA 0.554\n",
      "Beverage 0.555\n",
      "honorees 0.555\n",
      "Varsity 0.553\n",
      "Senior_Citizens 0.553\n",
      "Inglewood 0.554\n",
      "NAIA 0.554\n",
      "Marathon 0.555\n",
      "Methodist_Church 0.554\n",
      "Deaf 0.554\n",
      "College 0.552\n",
      "4A 0.554\n",
      "Fairmont 0.552\n",
      "Hillsboro 0.553\n",
      "Ceres 0.554\n",
      "Kiwanis 0.553\n",
      "Grenada 0.553\n",
      "JCC 0.553\n",
      "Olympian 0.557\n",
      "Area 0.552\n",
      "Maintenance 0.554\n",
      "Highlands 0.552\n",
      "Highland 0.553\n",
      "Lakeside 0.553\n",
      "Riverview 0.553\n",
      "Wildwood 0.553\n",
      "Goshen 0.553\n",
      "Farmington 0.553\n",
      "Hillside 0.552\n",
      "Barbados 0.556\n",
      "Lake 0.552\n",
      "Creek 0.552\n",
      "Reservoir 0.554\n",
      "Highland_Park 0.553\n",
      "Springfield 0.553\n",
      "USTA 0.556\n",
      "Pond 0.554\n",
      "San_Juan 0.554\n",
      "Lutheran 0.552\n",
      "Mennonite 0.553\n",
      "refuge 0.555\n",
      "Concordia 0.553\n",
      "Bremen 0.555\n",
      "Baptist 0.552\n",
      "Temple 0.552\n",
      "Calvary 0.552\n",
      "Nazarene 0.552\n",
      "Gym 0.554\n",
      "Jefferson 0.552\n",
      "Excelsior 0.553\n",
      "Majestic 0.554\n",
      "Woodbine 0.553\n",
      "Leukemia 0.557\n",
      "beautification 0.553\n",
      "beautify 0.554\n",
      "planters 0.555\n",
      "civic 0.553\n",
      "establishment 0.554\n",
      "modernization 0.555\n",
      "Cross_Country 0.554\n",
      "Roads 0.553\n",
      "Highways 0.554\n",
      "Secondary_School 0.554\n",
      "Colleges 0.554\n",
      "MCC 0.552\n",
      "SCC 0.554\n",
      "Amity 0.552\n",
      "Colfax 0.553\n",
      "Monrovia 0.553\n",
      "Sotheby 0.556\n",
      "Ripon 0.553\n",
      "Corridor 0.552\n",
      "Master_Plan 0.553\n",
      "Committees 0.554\n",
      "Westside 0.552\n",
      "Southside 0.552\n",
      "Northside 0.553\n",
      "RHS 0.555\n",
      "Macon 0.553\n",
      "Holy_Family 0.553\n",
      "RCN 0.557\n",
      "Eastside 0.552\n",
      "Clarksville 0.553\n",
      "Fayetteville 0.553\n",
      "Big_Brothers 0.555\n",
      "Porterville 0.554\n",
      "Crossroads 0.552\n",
      "Bluegrass 0.552\n",
      "Ozarks 0.553\n",
      "Olympians 0.557\n",
      "Blue_Ridge 0.553\n",
      "Ozark 0.553\n",
      "Decatur 0.553\n",
      "Greenville 0.553\n",
      "Westlake 0.554\n",
      "Littleton 0.554\n",
      "Oakwood 0.552\n",
      "Woodlawn 0.552\n",
      "Mount_Pleasant 0.553\n",
      "Northridge 0.554\n",
      "Academy 0.554\n",
      "Community_College 0.553\n",
      "Lyndon 0.554\n",
      "Avondale 0.553\n",
      "Agricultural 0.554\n",
      "Holstein 0.555\n",
      "Hilltop 0.552\n",
      "Grandview 0.553\n",
      "Arcadia 0.553\n",
      "Palisades 0.553\n",
      "HCC 0.554\n",
      "Polo 0.554\n",
      "GAC 0.554\n",
      "Gymnastics 0.555\n",
      "Mount_Vernon 0.552\n",
      "Coaches_Association 0.555\n",
      "Seneca 0.552\n",
      "Antigua 0.556\n",
      "Frankfort 0.552\n",
      "Chillicothe 0.553\n",
      "Rodeo 0.553\n",
      "Magnolia 0.553\n",
      "Dixie 0.553\n",
      "Rusty 0.555\n",
      "Cherokee 0.552\n",
      "Hickory 0.553\n",
      "Fulbright 0.555\n",
      "academy 0.556\n",
      "Hog 0.554\n",
      "Promoter 0.556\n",
      "Natchez 0.553\n",
      "Pearl_River 0.553\n",
      "Paso_Robles 0.554\n",
      "Saint_Joseph 0.553\n",
      "Prairie_View 0.554\n",
      "Regent 0.554\n",
      "Tudor 0.555\n",
      "CAC 0.554\n",
      "Little_Falls 0.554\n",
      "Edison 0.554\n",
      "Providence 0.553\n",
      "Stonewall 0.552\n",
      "MLK 0.552\n",
      "St. 0.553\n",
      "pm 0.554\n",
      "Girard 0.554\n",
      "Spectator 0.554\n",
      "Woodland 0.553\n",
      "Graduate 0.555\n",
      "Camden 0.553\n",
      "History 0.553\n",
      "Special_Olympics 0.555\n",
      "Versailles 0.553\n",
      "Colonial 0.551\n",
      "Neptune 0.554\n",
      "American_Legion 0.552\n",
      "Lackawanna 0.552\n",
      "Millers 0.554\n",
      "Renaissance 0.553\n",
      "Heidelberg 0.554\n",
      "Mark_Twain 0.553\n",
      "Explorers 0.554\n",
      "Hermitage 0.552\n",
      "vacant 0.554\n",
      "Williamsport 0.553\n",
      "Country 0.552\n",
      "Tea 0.553\n",
      "Mid 0.552\n",
      "WI 0.553\n",
      "KL 0.555\n",
      "Picnic 0.553\n",
      "Dominica 0.555\n",
      "Run 0.553\n",
      "Methodist 0.552\n",
      "First_Baptist_Church 0.553\n",
      "Xavier 0.555\n",
      "Triangle 0.552\n",
      "Outdoor 0.554\n",
      "Lowcountry 0.554\n",
      "Coastal 0.552\n",
      "Improvements 0.555\n",
      "San_Miguel 0.555\n",
      "Schools 0.554\n",
      "Emmanuel 0.556\n",
      "Riverfront 0.552\n",
      "Uptown 0.553\n",
      "graduating 0.556\n",
      "Boundary 0.553\n",
      "Eldorado 0.553\n",
      "Limestone 0.553\n",
      "Sycamore 0.553\n",
      "Bear_Creek 0.553\n",
      "Elk 0.553\n",
      "Granite 0.553\n",
      "Adirondack 0.554\n",
      "Wesleyan 0.553\n",
      "Junior 0.555\n",
      "Hospitality 0.554\n",
      "harness_racing 0.555\n",
      "Elon 0.554\n",
      "Heritage 0.551\n",
      "Historic 0.552\n",
      "Planned 0.553\n",
      "HOPE 0.553\n",
      "historic 0.553\n",
      "Scouts 0.554\n",
      "Landmark 0.552\n",
      "Legacy 0.552\n",
      "Civic 0.552\n",
      "Building 0.552\n",
      "Ivanhoe 0.555\n",
      "happenings 0.555\n",
      "Crescent 0.553\n",
      "Slough 0.555\n",
      "Cultural 0.553\n",
      "Tobacco 0.554\n",
      "Mentor 0.554\n",
      "Queens 0.554\n",
      "Christian 0.552\n",
      "Joseph 0.555\n",
      "Granada 0.555\n",
      "sociology 0.557\n",
      "Independence 0.55\n",
      "{'grd_high_conf': 256, 'grd_random_dist': 164, 'times_gradient': 420, 'times_exhaustive': 0, 'times_random': 5}\n"
     ]
    }
   ],
   "source": [
    "game = SemantleGame(w_vecs)\n",
    "player = SemantleSolver(game=game)\n",
    "print(game.target_word)\n",
    "print(player.CONF_THRESH)\n",
    "won = False\n",
    "while not won:\n",
    "    word = player.find_next_guess(w_vecs, ann_index, idx_to_word)\n",
    "    won = player.make_guess(word)\n",
    "    g = player.guesses[-1]\n",
    "    print(g.word, round(g.dist, 3))\n",
    "    if len(player.guesses) > 5000:\n",
    "        print('stopped. ')\n",
    "        print('Best guess:', player.best_guess, 'dist:', player.closest_dist)\n",
    "        break\n",
    "\n",
    "print(player.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493da4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47827ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search time.\n",
    "def run_trial(exh, n_rand, conf_thresh, w_vecs, idx_to_word, ann_index):\n",
    "    # make a game\n",
    "    \n",
    "    game = SemantleGame(w_vecs)\n",
    "    player = SemantleSolver(game=game)\n",
    "    \n",
    "    player.EXH_THRESH = exh\n",
    "    player.N_RANDOM = n_rand\n",
    "    player.CONF_THRESH = conf_thresh\n",
    "    \n",
    "    won = False\n",
    "    while not won:\n",
    "        word = player.find_next_guess(w_vecs, ann_index, idx_to_word)\n",
    "        won = player.make_guess(word)\n",
    "        if len(player.guesses) > 1000:\n",
    "            break\n",
    "    return len(player.guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e272e3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_glove_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0aef5630fcd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# set up space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mw_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_glove_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmat_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw_vecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_glove_file' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "n_dims = [10, 15, 20]\n",
    "exh_threshes = [0.001]\n",
    "n_randoms = [3]\n",
    "conf_threshes = [0.2, 0.3, 0.4, 0.6, 0.8]\n",
    "n_trials = 20\n",
    "\n",
    "params_results = {}\n",
    "\n",
    "for n_dim in n_dims:\n",
    "    \n",
    "    # set up space\n",
    "    w_vecs = read_glove_file()\n",
    "    pca = PCA(n_components=n_dim)\n",
    "    mat_full = np.array([w_vecs[w] for w in w_vecs])\n",
    "    mat = pca.fit_transform(mat_full)\n",
    "\n",
    "    for i, w in enumerate(w_vecs.keys()):\n",
    "        w_vecs[w] = mat[i, :]\n",
    "\n",
    "    idx_to_word, ann_index = build_index(w_vecs)\n",
    "\n",
    "    \n",
    "    for exh in exh_threshes:\n",
    "        for n_rand in n_randoms:\n",
    "            for conf_thresh in conf_threshes:\n",
    "                params = (n_dim, exh, n_rand, conf_thresh)\n",
    "                for trial in range(n_trials):\n",
    "                    n_guesses = run_trial(exh, n_rand, conf_thresh, w_vecs, idx_to_word, ann_index)\n",
    "                    if not params in params_results:\n",
    "                        params_results[params] = 0\n",
    "                    params_results[params] += n_guesses\n",
    "                params_results[params] /= n_trials\n",
    "                print(params, params_results[params])\n",
    "\n",
    "print(params_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3900178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(sorted(zip(params_results.items()), key=lambda x: x[1]))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906623da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list(sorted(zip(params_results.items()), key = lambda x: x[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945be112",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in ls:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc0c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84d6698d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UB'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now make something that plays Real Semantle\n",
    "s_play = SemantleSolver()\n",
    "s_play.add_guess('Central', 4.96)\n",
    "s_play.add_guess('Adventist',-5.61)\n",
    "s_play.add_guess('Heritage', 6.46)\n",
    "s_play.add_guess('Merchants', 5.95)\n",
    "s_play.add_guess('Union', -1.95)\n",
    "s_play.add_guess('Region', 1.54)\n",
    "s_play.add_guess('godzilla', 0.03)\n",
    "s_play.add_guess('fiscally_responsible', 17.59)\n",
    "s_play.add_guess('testimonies', -5.2)\n",
    "s_play.add_guess('meeting', 3.68)\n",
    "s_play.add_guess('liar', 16.14)\n",
    "s_play.add_guess('empire', 13.14)\n",
    "s_play.add_guess('stock', 27.98)\n",
    "s_play.add_guess('Capital', 26.33)\n",
    "s_play.find_next_guess(w_vecs, ann_index, idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd518a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5297fb78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
