{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888139a3",
   "metadata": {},
   "source": [
    "## Solving Semantle using locality-sensitive hashing (LSH)\n",
    "\n",
    "\n",
    "### 1. Build index\n",
    " - Read all GLoVe vectors from a file.\n",
    " - Build an LSH index on the GLoVe vector space.\n",
    "\n",
    "\n",
    "### 2. Set up a Semantle problem\n",
    " - Pick a random target word\n",
    " - Given a guess, compute the Euclidean distance from guess to target\n",
    " - Track guess history\n",
    " - Win when guess matches target (report number of guesses)\n",
    " \n",
    " \n",
    "### 3. Search using index\n",
    " - Explore phase:\n",
    "   - Randomly pick a word. Guess it.\n",
    "   - If close to target, move to exploit phase with this word.\n",
    "   - Otherwise, repeat.\n",
    "\n",
    " - Exploit phase:\n",
    "   - Get vector for your best guess word.\n",
    "   - Find neighbors. Guess those until you find a closer word. Don't guess a word you've already guessed.\n",
    "   - When you find a closer word, repeat.\n",
    "\n",
    "### 4. Test to find a good number for explore / exploit distance threshold\n",
    " - Repeatedly play Semantle with different thresholds\n",
    " - Find one that minimizes total number of guesses needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd28a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.spatial.distance import euclidean, pdist, squareform\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a43d2",
   "metadata": {},
   "source": [
    "## 1. Build index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63911e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_file() -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Yields the next 'size' vectors in a glove file.\n",
    "    \"\"\"\n",
    "    glove_file = '/mnt/Spookley/datasets/glove/glove.6B.50d.txt'\n",
    "    w_vecs = {}\n",
    "    with tqdm(total=400000) as pbar:\n",
    "        with open(glove_file) as fh:\n",
    "            for line in fh.readlines():\n",
    "                pbar.update(1)\n",
    "                toks = line.strip().split()\n",
    "                word = toks[0]\n",
    "                # non-words like punctuation marks have entries, but we don't want those\n",
    "                if not word.isalnum():  \n",
    "                    continue\n",
    "                # Some bigrams and trigrams are in the dataset. Skip those.\n",
    "                try:\n",
    "                    float(toks[1])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                # No errors, parse the line.\n",
    "                vec = [float(s) for s in toks[1:]]\n",
    "                w_vecs[word] = vec\n",
    "    return w_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fce618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b354f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(w_vecs: Dict[str, List[float]]) -> Tuple[Dict[int, str], AnnoyIndex]:\n",
    "    GLOVE_VEC_SIZE = 50\n",
    "    idx_to_word = {}\n",
    "    ann_index = AnnoyIndex(GLOVE_VEC_SIZE, 'euclidean')\n",
    "    with tqdm(total=len(w_vecs)) as pbar:\n",
    "        for i, w in enumerate(w_vecs.keys()):\n",
    "            pbar.update(1)\n",
    "            ann_index.add_item(i, w_vecs[w])\n",
    "            idx_to_word[i] = w\n",
    "    ann_index.build(20) # n trees\n",
    "    return idx_to_word, ann_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72504eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af5dd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba44ed6013ac41648dfde107fb195157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5b203fa822e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_glove_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-37cb2fedfe44>\u001b[0m in \u001b[0;36mread_glove_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mw_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w_vecs = read_glove_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c0aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_word, ann_index = build_index(w_vecs)  # Takes about an hour and a GB of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93867007",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index.save('ann_index.idx')\n",
    "import pickle\n",
    "with open('idx_to_word.pkl', 'wb') as fh:\n",
    "    pickle.dump(idx_to_word, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = w_vecs['wrath']\n",
    "items = ann_index.get_nns_by_vector(v, 20)\n",
    "for i in items:\n",
    "    print(i, idx_to_word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1932ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b79c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e230115",
   "metadata": {},
   "source": [
    "## 2. Set up a Semantle problemÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0bb8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemantleGame():\n",
    "    def __init__(self, w_vecs):\n",
    "        w_list = list(w_vecs.keys())\n",
    "        self.target_word = random.choice(w_list[1000:50000])\n",
    "        self.target_vec = w_vecs[self.target_word]\n",
    "        \n",
    "    def guess(self, word, vec) -> Tuple[bool, float]:\n",
    "        # construct guess\n",
    "        dist = euclidean(vec, self.target_vec)\n",
    "        # check if win\n",
    "        if word == self.target_word:\n",
    "            return True, dist\n",
    "        else:\n",
    "            return False, dist\n",
    "    \n",
    "    def display_guesses(self):\n",
    "        s = []\n",
    "        for g in sorted(self.guesses, key = lambda g: g.dist):\n",
    "            s.append(str(g))\n",
    "        print('\\n'.join(s))\n",
    "        \n",
    "    def __str__(self):\n",
    "        return '\\n'.join('{}: {}'.format(k, v) for k, v in self.__dict__.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b070cc45",
   "metadata": {},
   "source": [
    "## 2. Search using index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dfd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_weighted_centroid(points, dists):\n",
    "    # compute weighted centroid of the points. \n",
    "    # Close to target = higher weight.\n",
    "    D = sum(dists)\n",
    "    centroid = np.zeros((1, points.shape[1]))\n",
    "    tot_weight = 0\n",
    "    for i in range(len(points)):\n",
    "        wi = D/max(dists[i], 0.00001)\n",
    "        centroid += points[i]*wi\n",
    "        tot_weight += wi\n",
    "    return centroid / tot_weight\n",
    "\n",
    "class SemantleSolver:\n",
    "    \n",
    "    def __init__(self, game: SemantleGame, n_random_guesses=10):\n",
    "        self.game = game\n",
    "        self.n_random_guesses = n_random_guesses\n",
    "        self.closest_dist = float('inf')\n",
    "        self.guesses = {}  # Dict[str: (float, int)] of {word: (dist, guess_num)}\n",
    "        self.best_guess = None\n",
    "\n",
    "    \n",
    "    def guess(self, w_vecs, ann_index, idx_to_word) -> bool:\n",
    "        # determine next guess\n",
    "        g_type = 'random:'\n",
    "        if len(self.guesses) < self.n_random_guesses:\n",
    "            next_word = random.choice(list(w_vecs.keys()))\n",
    "        \n",
    "        if self.best_guess is not None and self.closest_dist <= self.dist_thresh:\n",
    "            g_type = 'nearby:'\n",
    "            # 'exploit' - guess words near our best candidate\n",
    "            idxs_near_best = ann_index.get_nns_by_vector(v, 10000)\n",
    "            for idx in idxs_near_best:\n",
    "                w = idx_to_word[idx]\n",
    "                if w not in self.guesses:\n",
    "                    next_word = w\n",
    "                    break\n",
    "        else:\n",
    "            next_word = random.choice(list(w_vecs.keys()))\n",
    "        \n",
    "        # guess the word\n",
    "        win, dist = self.game.guess(next_word, w_vecs[next_word])\n",
    "        self.guesses[next_word] = (dist, len(self.guesses)+1)\n",
    "\n",
    "        # see if this one's better\n",
    "        if self.best_guess is None or dist < self.closest_dist:\n",
    "            print(g_type, next_word, \"dist:\", dist, \"best:\", \n",
    "                  self.best_guess, \"best_dist:\", self.closest_dist, \"guesses:\", len(self.guesses))\n",
    "            self.closest_dist = dist\n",
    "            self.best_guess = next_word\n",
    "        \n",
    "        if win:\n",
    "            print(\"I win!\", self.guesses)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baeeabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = SemantleGame(w_vecs)\n",
    "player = SemantleSolver(game, n_random_guesses=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd09c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(game.target_word)\n",
    "won = False\n",
    "while not won:\n",
    "    won = player.guess(w_vecs, ann_index, idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_weighted_centroid(points, dists):\n",
    "    # compute weighted centroid of the points. \n",
    "    # Close to target = higher weight.\n",
    "    D = sum(dists)\n",
    "    centroid = np.zeros((1, points.shape[1]))\n",
    "    tot_weight = 0\n",
    "    for i in range(len(points)):\n",
    "        wi = D/max(dists[i], 0.00001)\n",
    "        centroid += points[i]*wi\n",
    "        tot_weight += wi\n",
    "    return centroid / tot_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39695a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.random.random((5, 2))\n",
    "target = np.random.random((1, 2))\n",
    "dists = [euclidean(target,pi) for pi in points]\n",
    "\n",
    "centroid = dist_weighted_centroid(points, dists)\n",
    "print(centroid)\n",
    "plt.xlim(0, 1.0)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.plot(points[:,0], points[:, 1], 'b.')\n",
    "plt.plot(centroid[0][0], centroid[0][1], 'g.')\n",
    "plt.plot(target[0][0], target[0][1], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c06a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_aimbot(n_points, n_dims) -> float:\n",
    "    # generate some random points\n",
    "    points = np.random.random((n_points, n_dims))\n",
    "\n",
    "    # we're going to try and find this target point\n",
    "    target = np.random.random((1, n_dims))\n",
    "    \n",
    "    # find dist from each point to the target\n",
    "    dists = [euclidean(target,pi) for pi in points]\n",
    "    \n",
    "    centroid = dist_weighted_centroid(points, dists)[0]\n",
    "    \n",
    "    centroid_dist = euclidean(centroid, target)\n",
    "    \n",
    "    # find vec from each point to the centroid\n",
    "    for i in range(points.shape[0]):\n",
    "        vec_pc = centroid - point\n",
    "        vec_pc_mag = scipy.linalg.norm(p1c)\n",
    "        if centroid_dist < dists[i]:\n",
    "            \n",
    "    \n",
    "    # find vector from point i to point j for each (i, j) pair. \n",
    "    # Multiply each vector by (dist[i]-dist[j]).\n",
    "    vecs = []\n",
    "    target_points = []\n",
    "    target_confidences = []\n",
    "    for i in range(points.shape[0]):\n",
    "        for j in range(i+1, points.shape[0]):\n",
    "            p1p2 = (points[j]-points[i])\n",
    "            p1p2mag = scipy.linalg.norm(p1p2)\n",
    "            p1p2_unit = p1p2 / p1p2mag\n",
    "            if dists[i] < dists[j]:\n",
    "                mag = dists[i]\n",
    "                target_point = points[i] - p1p2_unit*mag\n",
    "                confidence = (dists[j]-dists[i]) / p1p2mag\n",
    "            else:\n",
    "                # j is closer to target\n",
    "                # make a vector from j to a target that is dists[j] away\n",
    "                mag = dists[j]\n",
    "                target_point = points[j] + p1p2_unit*mag\n",
    "                confidence = (dists[i]-dists[j]) / p1p2mag\n",
    "            #print(points[i], points[j], target_point, confidence)\n",
    "            target_points.append(target_point)\n",
    "            target_confidences.append(confidence**2)\n",
    "    \n",
    "    target_centroid = dist_weighted_centroid(np.array(target_points), target_confidences)[0]\n",
    "    #vec_weighted = sum(w_vecs)\n",
    "    #vec_weighted = vec_weighted / tot_mag\n",
    "    \n",
    "    # our best guess is that the target is centroid + vec_weighted.\n",
    "    # Return the error.\n",
    "    #guess_point = centroid+vec_weighted\\\n",
    "    #print(sum(target_confidences)/len(target_confidences))\n",
    "    target_weight = np.max(target_confidences)\n",
    "    guess_point = centroid + target_weight*(target_centroid-centroid)\n",
    "    return points, target, centroid, target_centroid, guess_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb9fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "points, target, centroid, target_centroid, guess = test_aimbot(8, 2)\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(-0.5, 1.5)\n",
    "plt.plot(points[:,0], points[:, 1], 'b.')\n",
    "plt.plot(centroid[0], centroid[1], 'g.')\n",
    "plt.plot(target[0][0], target[0][1], 'ro')\n",
    "plt.plot(guess[0], guess[1], 'gx')\n",
    "guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca2c6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcaf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_dims = 50\n",
    "n_trials = 10\n",
    "results = []\n",
    "for n_points in range(3,50):\n",
    "    result = 0\n",
    "    for trial in range(n_trials):\n",
    "        points, target, centroid, target_centroid, guess_point = test_aimbot(n_points, n_dims)\n",
    "        result += euclidean(centroid, target)\n",
    "    results.append(result / n_trials)\n",
    "plt.plot(results)\n",
    "plt.title('Guess error in a {}-dimensional space'.format(n_dims))\n",
    "plt.xlabel('number of guesses')\n",
    "plt.ylabel('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1,1,1,1,1,1,])\n",
    "v2 = np.array([1,0,0,1,1,1,])\n",
    "v3 = np.array([1,0,3,1,0,3,])\n",
    "v4 = np.array([5,2,3,1,2,3,])\n",
    "v5 = np.array([4,0,3,3,4,9,])\n",
    "\n",
    "vecs = np.array([v1, v2, v3, v4, v5])\n",
    "\n",
    "target = np.array([5, 1.5, 5, 1.5, 5, 1.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772c4d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fee7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d11af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate = centroid + vec_weighted\n",
    "print(target-centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0314008",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random((1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f086d24d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
